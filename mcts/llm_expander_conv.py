import json
import re
from typing import Dict, Any, Optional, List
from utils import initialize_llm, calculate_memory_usage
from mcts_node import ArchitectureNode
from models import CandidateModel
from nas import MemoryEstimator
import time
from Proxyless.zero_cost_proxies import ZeroCostProxies
import torch

def load_mhealth_architectures(file_path: str):
    """åŠ è½½ Mhealth æ•°æ®é›†çš„æ¶æ„ä¿¡æ¯"""
    with open(file_path, 'r') as f:
        architectures = json.load(f)
    return architectures

# æ·»åŠ è‡ªå®šä¹‰å¼‚å¸¸ç±»
class CandidateQualityException(Exception):
    """å€™é€‰è´¨é‡ä¸è¾¾æ ‡å¼‚å¸¸"""
    def __init__(self, failure_report: Dict):
        self.failure_report = failure_report
        super().__init__(f"å€™é€‰è´¨é‡ä¸è¾¾æ ‡: {failure_report['valid_count']}/5 é€šè¿‡éªŒè¯")

class LLMConvExpander:
    """åŸºäºLLMçš„æ¶æ„æ‰©å±•å™¨ï¼Œè´Ÿè´£ç”Ÿæˆæ–°çš„æ¶æ„"""
    
    def __init__(self, llm_config: Dict[str, Any], search_space: Dict[str, Any], dataset_info: Dict[str, Any] = None, mcts_graph=None):
        self.llm = initialize_llm(llm_config)
        self.search_space = search_space
        self.dataset_info = dataset_info or {}  # æ–°å¢ï¼š å­˜å‚¨æ•°æ®é›†ä¿¡æ¯
        self.max_retries = 3
        self.mcts_graph = mcts_graph  # æ–°å¢ï¼š éœ€è¦å›¾ç»“æ„æ¥è·å–å…³ç³»ä¿¡æ¯
        self.current_valid_candidates = None
        self.valid_threshold = 3
        
    def set_mcts_graph(self, mcts_graph):
        """è®¾ç½®MCTSå›¾ç»“æ„å¼•ç”¨"""
        self.mcts_graph = mcts_graph

    def set_dataset_info(self, dataset_info: Dict[str, Any]):
        """è®¾ç½®æ•°æ®é›†ä¿¡æ¯"""
        self.dataset_info = dataset_info
        
    def expand_from_parent(self, parent_node: ArchitectureNode, dataset_name: str, 
                          dataset_info: Dict[str, Any], pareto_feedback: str, 
                          constraint_feedback: Optional[str] = None,
                          global_successes: List[Dict] = None,  # æ–°å¢å‚æ•°
                          global_failures: List[Dict] = None) -> Optional[CandidateModel]:
        """åŸºäº çˆ¶èŠ‚ç‚¹ å’Œ åé¦ˆç”Ÿæˆæ–°çš„æ¶æ„"""
        
        # æ”¶é›†å½“å‰ä¼šè¯çš„çº¦æŸè¿åå†å²
        session_failures = []
        validation_feedback = constraint_feedback
        last_valid_candidates = []  # å­˜å‚¨æœ€åä¸€æ¬¡ç”Ÿæˆçš„å€™é€‰æ¶æ„
        all_valid_candidates = []   # å­˜å‚¨æ‰€æœ‰å°è¯•ä¸­é€šè¿‡éªŒè¯çš„å€™é€‰
        self.current_valid_candidates = []

        for attempt in range(self.max_retries):
            try:
                print(f"ğŸ¤– LLMæ‰©å±•å°è¯• {attempt + 1}/{self.max_retries}")
                
                # æ„å»ºæ‰©å±•ä¸Šä¸‹æ–‡
                context = self._build_expansion_context(parent_node, dataset_name, dataset_info, pareto_feedback,
                                                        validation_feedback, session_failures,
                                                        global_successes, global_failures  # ä¼ é€’å…¨å±€ç»éªŒ
                                                        )
                print(f"context is over.\n")
                # ç”Ÿæˆæ‰©å±•æç¤º - ç°åœ¨è¦æ±‚ç”Ÿæˆ5ä¸ªå€™é€‰
                prompt = self._build_multiple_candidates_prompt(context)
                
                print(f"prompt is over.\n")
                # è°ƒç”¨LLM
                response = self.llm.invoke(prompt).content
                print(f"-----------------LLMå“åº”-----------------\n {response}")
                
                # è§£æå“åº”
                candidates = self._parse_multiple_candidates_response(response)

                if not candidates:
                    session_failures.append({
                        'attempt': attempt + 1,
                        'failure_type': 'parsing_failed',
                        'suggestion': 'Please ensure all 5 JSON configurations are correct and contain all required fields.',
                        'candidates_parsed': 0,
                        'required_candidates': 5
                    })
                    validation_feedback = f"""PARSING FAILED IN ATTEMPT {attempt + 1}:
                    - Failed to parse 5 valid JSON configurations
                    - Please ensure JSON format is correct
                    - All candidates must contain required fields: stages, input_channels, num_classes
                    """
                    continue
                
                # ä¿å­˜æœ€åä¸€æ¬¡ç”Ÿæˆçš„å€™é€‰æ¶æ„
                last_valid_candidates = candidates

                # è¯„å®¡å’Œé€‰æ‹©æœ€ä½³å€™é€‰ - ç°åœ¨åŒ…å«è´¨é‡æ§åˆ¶
                try:
                    best_candidate, current_valid_candidates = self._review_and_select_candidate(
                        candidates, dataset_name, attempt, session_failures, all_valid_candidates
                    )
                    # å°†æœ¬æ¬¡å°è¯•çš„éªŒè¯é€šè¿‡çš„å€™é€‰æ·»åŠ åˆ°æ€»åˆ—è¡¨ä¸­
                    all_valid_candidates.extend(current_valid_candidates)

                    if best_candidate is None:
                        # å¦‚æœæ‰€æœ‰å€™é€‰éƒ½ä¸åˆæ ¼ï¼Œè®°å½•å¤±è´¥ä¿¡æ¯
                        session_failures.append({
                            'attempt': attempt + 1,
                            'failure_type': 'all_candidates_failed',
                            'suggestion': 'Unexpected error: no candidate selected despite passing quality control.'
                        })
                        continue
                    # é€‰æ‹©çš„å€™é€‰æ¶æ„
                    print(f"âœ… é€‰æ‹©æœ€ä½³å€™é€‰æ¶æ„ (å°è¯• {attempt + 1})")
                    return best_candidate
                
                except CandidateQualityException as e:
                    # æ•è·è´¨é‡æ§åˆ¶å¤±è´¥
                    failure_report = e.failure_report
                    valid_count = failure_report['valid_count']
                    print(f"âŒ å€™é€‰è´¨é‡æ§åˆ¶å¤±è´¥: {valid_count}/5 é€šè¿‡éªŒè¯")

                    # å³ä½¿è´¨é‡æ§åˆ¶å¤±è´¥ï¼Œä¹Ÿè¦å°†æœ¬æ¬¡é€šè¿‡çš„å€™é€‰æ·»åŠ åˆ°æ€»åˆ—è¡¨ä¸­
                    if self.current_valid_candidates:  # ç¡®ä¿ current_valid_candidates åœ¨ try å—å¤–å¯è®¿é—®
                        all_valid_candidates.extend(self.current_valid_candidates)
                        print(f"ğŸ“ å°† {len(self.current_valid_candidates)} ä¸ªé€šè¿‡éªŒè¯çš„å€™é€‰æ·»åŠ åˆ°æ€»åˆ—è¡¨")

                    # æ„å»ºè¯¦ç»†çš„å¤±è´¥åé¦ˆ
                    validation_feedback = self._build_quality_failure_feedback(failure_report, attempt)
                    # è®°å½•åˆ°session_failures
                    session_failures.append({
                        'attempt': attempt + 1,
                        'failure_type': 'quality_control_failed',
                        'valid_count': failure_report['valid_count'],
                        'pass_rate': failure_report['pass_rate'],
                        'failure_reasons': failure_report['failure_reasons'],
                        'improvement_suggestions': failure_report['improvement_suggestions'],
                        'suggestion': f"Only {failure_report['valid_count']}/5 candidates passed validation. Need at least 3 valid candidates."
                    })
                    continue
                     
            except Exception as e:
                print(f"LLMæ‰©å±•å¤±è´¥: {str(e)}")
                session_failures.append({
                    'attempt': attempt + 1,
                    'failure_type': 'exception',
                    'suggestion': f'Error occurred: {str(e)}'
                })

        # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œåˆ™ä»æ‰€æœ‰é€šè¿‡éªŒè¯çš„å€™é€‰ä¸­é€‰æ‹©æœ€ä½³å€™é€‰
        if all_valid_candidates:
            print(f"âš ï¸ æ‰€æœ‰å°è¯•å‡å¤±è´¥ï¼Œä»ç´¯è®¡çš„ {len(all_valid_candidates)} ä¸ªé€šè¿‡éªŒè¯çš„å€™é€‰ä¸­é€‰æ‹©æœ€ä½³å€™é€‰...")
            
            # è¿‡æ»¤æ‰é‡å¤çš„å€™é€‰
            unique_valid_candidates = []
            for cand_info in all_valid_candidates:
                if not self._is_duplicate(cand_info['candidate']):
                    unique_valid_candidates.append(cand_info)
            
            if unique_valid_candidates:
                # æŒ‰ç…§å†…å­˜åˆ†æ•°æ’åºï¼ˆä»é«˜åˆ°ä½ï¼‰
                unique_valid_candidates.sort(key=lambda x: x['memory_score'], reverse=True)
                
                best_candidate_info = unique_valid_candidates[0]
                best_candidate = best_candidate_info['candidate']
                
                print(f"{'=' * 20}\nğŸ¯ åå¤‡é€‰æ‹©æœ€ä½³å€™é€‰:\n{'=' * 20}\n")
                print(f"   å†…å­˜åˆ†æ•°: {best_candidate_info['memory_score']:.3f}")
                print(f"   æœ‰æ•ˆå†…å­˜: {best_candidate_info['effective_memory']:.1f}MB")
                print(f"   é‡åŒ–æ¨¡å¼: {best_candidate_info['quant_mode']}")
                print(f"   æ¨¡å‹æ¶æ„ï¼š{best_candidate}")
                return best_candidate
            else:
                print("âŒ æ‰€æœ‰é€šè¿‡éªŒè¯çš„æ¶æ„éƒ½æ˜¯é‡å¤çš„")

        print("âŒ å®Œå…¨æ— æ³•ç”Ÿæˆç¬¦åˆæ¡ä»¶çš„å€™é€‰æ¶æ„")
        return None
    
    def _build_quality_failure_feedback(self, failure_report: Dict, attempt: int) -> str:
        """æ„å»ºè´¨é‡æ§åˆ¶å¤±è´¥çš„åé¦ˆä¿¡æ¯"""
        feedback_parts = [
            f"QUALITY CONTROL FAILED IN ATTEMPT {attempt + 1}:",
            f"- Only {failure_report['valid_count']}/5 candidates passed validation (need â‰¥3)",
            f"- Pass rate: {failure_report['pass_rate']:.1%}"
        ]
        
        # æ·»åŠ å…·ä½“å¤±è´¥åŸå› 
        if failure_report['failure_reasons']:
            feedback_parts.append("- Specific failure reasons:")
            for failure_type, failures in failure_report['failure_reasons'].items():
                if failure_type == 'memory_constraint':
                    feedback_parts.append(f"  * Memory violations: {len(failures)} candidates")
                elif failure_type == 'latency_constraint':
                    feedback_parts.append(f"  * Latency violations: {len(failures)} candidates")
                elif failure_type == 'parsing_error':
                    feedback_parts.append(f"  * Parsing errors: {len(failures)} candidates")
        
        # æ·»åŠ æ”¹è¿›å»ºè®®
        feedback_parts.append("- Improvement strategies:")
        feedback_parts.append(failure_report['improvement_suggestions'])
        
        # æ·»åŠ å†…å­˜åˆ†æ
        if failure_report['memory_analysis']:
            feedback_parts.append(f"- {failure_report['memory_analysis']}")
        
        feedback_parts.append("- CRITICAL: Generate 5 candidates with at least 3 passing all constraints!")
        
        return "\n".join(feedback_parts)

    def _validate_candidate(self, candidate: CandidateModel, dataset_name: str) -> tuple:
        """éªŒè¯å€™é€‰æ¶æ„çš„çº¦æŸæ¡ä»¶"""
        violations = []
        suggestions = []
        
        # æ£€æŸ¥ SeDpConv block çš„çº¦æŸ
        stages = candidate.config.get("stages", [])
        input_channels = candidate.config.get("input_channels", None)

        if not input_channels:
            return False, "Missing input_channels in candidate configuration", "Ensure input_channels is defined in the configuration."
        
        for stage_index, stage in enumerate(stages):
            stage_channels = stage.get("channels", None)
            if not stage_channels:
                return False, f"Stage {stage_index + 1} missing channels", f"Ensure channels are defined for stage {stage_index + 1}."
            
            for block in stage.get("blocks", []):
                if block.get("type") == "SeDpConv":
                    # æ£€æŸ¥ SeDpConv çš„ channels æ˜¯å¦ç¬¦åˆè¦æ±‚
                    if stage_index == 0:
                        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ª stageï¼Œæ£€æŸ¥ input_channels æ˜¯å¦ç­‰äº stage çš„ channels
                        if stage_channels != input_channels:
                            print(f"SeDpConv in channels != out channels!")
                            violations.append(f"Stage {stage_index + 1} SeDpConv block violation: input_channels ({input_channels}) != stage_channels ({stage_channels})")
                            suggestions.append("- Ensure the input_channels match the stage_channels for the first stage.")
                    else:
                        # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ª stageï¼Œæ£€æŸ¥å‰ä¸€ä¸ª stage çš„ channels æ˜¯å¦ç­‰äºå½“å‰ stage çš„ channels
                        prev_stage_channels = stages[stage_index - 1].get("channels", None)
                        if prev_stage_channels != stage_channels:
                            print(f"SeDpConv in channels != out channels!")
                            violations.append(f"Stage {stage_index + 1} SeDpConv block violation: prev_stage_channels ({prev_stage_channels}) != stage_channels ({stage_channels})")
                            suggestions.append("- Ensure the previous stage's channels match the current stage's channels for SeDpConv blocks.")

        # è·å–æ•°æ®é›†ä¿¡æ¯
        if dataset_name not in self.dataset_info:
            return True, "", ""  # å¦‚æœæ²¡æœ‰æ•°æ®é›†ä¿¡æ¯ï¼Œè·³è¿‡éªŒè¯
            
        dataset_info = self.dataset_info[dataset_name]
        
        if violations:
            return False, " | ".join(violations), "\n".join(suggestions)
        
        # è®¡ç®—å†…å­˜ä½¿ç”¨é‡
        memory_usage = calculate_memory_usage(
            candidate.build_model(),
            input_size=(64, dataset_info['channels'], dataset_info['time_steps']),
            device='cpu'
        )
        
        activation_memory_mb = memory_usage['activation_memory_MB']
        parameter_memory_mb = memory_usage['parameter_memory_MB']
        total_memory_mb = memory_usage['total_memory_MB']
        
        # è®¾ç½®å€™é€‰æ¨¡å‹çš„å†…å­˜ä¿¡æ¯
        candidate.estimate_total_size = total_memory_mb
        candidate.metadata['activation_memory_MB'] = activation_memory_mb
        candidate.metadata['parameter_memory_MB'] = parameter_memory_mb
        candidate.metadata['estimated_total_size_MB'] = total_memory_mb

        # è·å–çº¦æŸé™åˆ¶
        max_peak_memory = float(self.search_space['constraints'].get('max_peak_memory', float('inf'))) / 1e6
        quant_mode = candidate.config.get('quant_mode', 'none')

        # å¦‚æœé‡åŒ–æ¨¡å¼ä¸º staticï¼Œåˆ™å°†å†…å­˜ä¼°ç®—å€¼é™¤ä»¥ 4
        # ä¿®æ­£ï¼šæ ¹æ®é‡åŒ–æ¨¡å¼è°ƒæ•´æœ‰æ•ˆå†…å­˜ä½¿ç”¨é‡å’Œé™åˆ¶
        if quant_mode == 'static' or quant_mode == 'qat':
            effective_memory = total_memory_mb / 4  # é‡åŒ–åå†…å­˜ä¸ºåŸæ¥çš„1/4
            effective_limit = max_peak_memory  # æœ€ç»ˆé™åˆ¶ä¿æŒä¸å˜
            memory_context = f"é‡åŒ–å‰: {total_memory_mb:.2f}MB â†’ é‡åŒ–å: {effective_memory:.2f}MB"
            print(f"âš™ï¸ é™æ€é‡åŒ–æ¨¡å¼: {memory_context}")
        else:
            effective_memory = total_memory_mb
            effective_limit = max_peak_memory
            memory_context = f"æ— é‡åŒ–: {effective_memory:.2f}MB"
        
        # æ£€æŸ¥å†…å­˜çº¦æŸ - ä½¿ç”¨æœ‰æ•ˆå†…å­˜å’Œé™åˆ¶
        estimated_total_size_status = f"Estimated Total Size: {memory_context}"
        
        # ä¿®æ­£çº¦æŸæ£€æŸ¥é€»è¾‘
        if effective_memory > 4 * effective_limit:
            estimated_total_size_status += f" (Exceeding 4x the maximum value {4 * effective_limit:.2f}MB)"
            violations.append(estimated_total_size_status)
            suggestions.append("- Reduce the number of stages greatly.\n"
                            "- Reduce model size by removing redundant blocks\n" 
                            "- Consider quantization\n"
                            "- Use DWSeqConv or DpConv or SeSepConv or SeDpConv instead of MBConv.\n"
                            "- SeDpConv is the lightest block.\n")
            print(f"âŒ æ¶æ„è¢«æ‹’ç»: æœ‰æ•ˆå†…å­˜ {effective_memory:.2f}MB è¶…è¿‡4å€é™åˆ¶")
            
        elif effective_memory > effective_limit:
            estimated_total_size_status += f" (Exceeding the maximum value {effective_limit:.2f}MB, but within 4x)"
            violations.append(estimated_total_size_status)
            
            if quant_mode == 'none':
                suggestions.append("- Consider applying quantization (quant_mode: 'static', 'qat')\n"
                                "- Static or QAT quantization can reduce memory to 1/4\n"
                                "- Reducing the number of stages is the most significant method.\n"
                                "- Besides, you can replace MBConv with DWSeqConv/DpConv/SeSepConv/SeDpConv, which is the very effective method!\n"
                                "- The SE module will increase memory overhead, and if the memory limit is strict, it can be set to False.\n")
            else:
                suggestions.append("- Reduce the number of stages appropriately.\n"
                                "- For both DWSeqConv and MBConv, the number of channels can be appropriately reduced kernel size.\n"
                                "- Among them, MBConv can also reduce expansion appropriately!\n"
                                "- Besides, you can replace MBConv with DWSeqConv/DpConv/SeSepConv/SeDpConv, which is the very effective method!\n"
                                "(However, please note that when expansion=1, MBConv will have the same effect as DWSeqConv)")
            print(f"âš ï¸ æ¶æ„éœ€è¦ä¼˜åŒ–: æœ‰æ•ˆå†…å­˜ {effective_memory:.2f}MB è¶…è¿‡é™åˆ¶")
        else:
            estimated_total_size_status += " (Compliant with constraints)"
            print(f"âœ… å†…å­˜çº¦æŸæ£€æŸ¥é€šè¿‡: {memory_context}")

        # æ£€æŸ¥å»¶è¿Ÿçº¦æŸ
        latency = candidate.measure_latency(device='cpu', dataset_names=dataset_name)
        max_latency = float(self.search_space['constraints'].get('max_latency', float('inf')))
        latency_status = f"Latency: {latency:.2f}ms"
        
        if latency > max_latency:
            latency_status += f" (Exceeding the maximum value {max_latency:.2f}ms)"
            violations.append(latency_status)
            suggestions.append("- Optimize convolution operations\n"
                               "- Reduce the number of blocks in each stage\n"
                               "- Use depthwise separable convolutions\n"
                               "- Consider model quantization")
        else:
            latency_status += " (Compliant with constraints)"
        
        # æ‰“å°éªŒè¯ç»“æœ
        print("\n---- çº¦æŸéªŒè¯ç»“æœ ----")
        print(f"estimated_total_size_MB: {total_memory_mb} MB")
        print(f"latency_status: {latency} ms")
        print("----------------------")
        
        if violations:
            return False, " | ".join(violations), "\n".join(suggestions)
        return True, "", ""
    

    def _build_expansion_context(self, parent_node: ArchitectureNode, dataset_name: str,
                               dataset_info: Dict[str, Any], pareto_feedback: str,
                               constraint_feedback: Optional[str] = None, 
                               session_failures: List[Dict] = None,
                               global_successes: List[Dict] = None,  # æ–°å¢å‚æ•°
                               global_failures: List[Dict] = None) -> Dict[str, Any]:
        """æ„å»ºæ‰©å±•ä¸Šä¸‹æ–‡"""
        context = {
            'dataset_name': dataset_name,
            'dataset_info': dataset_info,
            'pareto_feedback': pareto_feedback,
            'search_space': self.search_space,
            'constraint_feedback': constraint_feedback,
            'session_failures': session_failures or []
        }
        
        # å¤„ç†çˆ¶èŠ‚ç‚¹ä¿¡æ¯ - å¦‚æœçˆ¶èŠ‚ç‚¹ä¸ºç©ºæˆ–æ²¡æœ‰å€™é€‰
        if parent_node is None or parent_node.candidate is None:
            print("âš ï¸ çˆ¶èŠ‚ç‚¹ä¸ºç©ºï¼Œä½¿ç”¨ç©ºä¸Šä¸‹æ–‡")
            context['parent_architecture'] = None
        else:
            print(f"ä½¿ç”¨çˆ¶èŠ‚ç‚¹ä¿¡æ¯\n{'-' * 20}\nparent_node.candidate: {parent_node.candidate}")
            context['parent_architecture'] = {
                'config': parent_node.candidate.config,
                'performance': {
                    'accuracy': parent_node.accuracy,
                    'memory_usage': parent_node.memory_usage,
                    'latency': parent_node.latency,
                    'quantization_mode': parent_node.quantization_mode,
                    'quantized_accuracy': parent_node.quantized_accuracy if parent_node.quantized_accuracy is not None else None,
                    'quantized_memory': parent_node.quantized_memory,
                    'quantized_latency': parent_node.quantized_latency
                },
                'mcts_stats': {
                    'visits': parent_node.visits,
                    'score': parent_node.score,
                    'is_evaluated': parent_node.is_evaluated
                }
            }
        
        # ä½¿ç”¨å…¨å±€ç»éªŒè€Œä¸æ˜¯çˆ¶èŠ‚ç‚¹çš„ç»éªŒ
        context['experience'] = {
            'successful_modifications': (global_successes or [])[-3:],  # æœ€è¿‘3æ¡å…¨å±€æˆåŠŸç»éªŒ
            'failed_modifications': (global_failures or [])[-3:]        # æœ€è¿‘3æ¡å…¨å±€å¤±è´¥ç»éªŒ
        }
        
        return context
    
    def _build_multiple_candidates_prompt(self, context: Dict[str, Any]) -> str:
        """æ„å»ºLLMæ‰©å±•æç¤º"""

        dataset_info = context['dataset_info']
        # å‡†å¤‡çˆ¶èŠ‚ç‚¹ä¿¡æ¯
        parent_info = "None"
        if context.get('parent_architecture') is not None and 'parent_architecture' in context:
            parent = context['parent_architecture']
            parent_info = f"""
            - Accuracy: {parent['performance']['accuracy']:.2f}%
            - Memory: {parent['performance']['memory_usage']:.1f}MB
            - Latency: {parent['performance']['latency']:.1f}ms
            - Quantization: {parent['performance']['quantization_mode']}
            - MCTS Score: {parent['mcts_stats']['score']:.3f}
            - Visits: {parent['mcts_stats']['visits']}
            - Evaluated: {parent['mcts_stats']['is_evaluated']}
            - Configuration: {json.dumps(parent['config'], indent=2)}"""

            # å¦‚æœæ¶æ„å¼€å¯äº†é‡åŒ–ï¼Œè¡¥å……é‡åŒ–å‰åçš„å‡†ç¡®ç‡å¯¹æ¯”
            if parent['performance']['quantization_mode'] != 'none':
                quantized_accuracy = parent['performance'].get('quantized_accuracy', 'N/A')
                if isinstance(quantized_accuracy, (int, float)):
                    parent_info += f"""
                    - Quantized Accuracy: {quantized_accuracy:.2f}%
                    - Accuracy Drop: {parent['performance']['accuracy'] - quantized_accuracy:.2f}%
                    """
                else:
                    parent_info += f"""
                    - Quantized Accuracy: {quantized_accuracy}
                    - Accuracy Drop: N/A
                    """
        else:
            parent_info = "None (åˆå§‹èŠ‚ç‚¹ï¼Œæ— çˆ¶æ¶æ„)"
            
        # æ·»åŠ Paretoå‰æ²¿åé¦ˆ ï¼ˆä¿æŒä¸å˜ï¼‰  æˆ‘ä¸æ‰“ç®—åŠ åœ¨ prompt é‡Œäº†
        if context['pareto_feedback']:
            feedback = context.get('pareto_feedback', "No Pareto frontier feedback")


        # ä¿®æ­£ï¼šå‡†å¤‡å¤±è´¥æ¡ˆä¾‹ä¿¡æ¯ - å…³æ³¨æ€§èƒ½ä¸‹é™çš„ä¿®æ”¹
        failure_feedback = "None"
        if 'experience' in context and context['experience']['failed_modifications']:
            last_failures = context['experience']['failed_modifications'][-3:]
            failure_cases = []
            for f in last_failures:  
                #   ï¼ˆæ€§èƒ½ä¸‹é™ï¼‰
                if f.get('type') == 'arch_expansion' and f.get('result_type') == 'failure':
                    case_info = f"- Score Change: {f.get('improvement', 0):.3f} (decreased)"
                    if 'config_diff' in f:
                        case_info += f"\n  Config Changes: {json.dumps(f['config_diff'], indent=2)}"
                    if 'failure_reason' in f:
                        case_info += f"\n  Reason: {f['failure_reason']}"
                    case_info += f"\n  Parent Score: {f.get('parent_score', 0):.3f} â†’ Current Score: {f.get('current_score', 0):.3f}"
                    failure_cases.append(case_info)
            
            if failure_cases:
                failure_feedback = "\n".join(failure_cases)

        # ä¿®æ­£ï¼šå‡†å¤‡æˆåŠŸæ¡ˆä¾‹ä¿¡æ¯ - å…³æ³¨æ€§èƒ½æå‡çš„ä¿®æ”¹
        success_feedback = "None"
        if 'experience' in context and context['experience']['successful_modifications']:
            last_successes = context['experience']['successful_modifications'][-3:]
            success_cases = []
            for s in last_successes:
                # åªå¤„ç†æ¶æ„æ‰©å±•ç±»å‹çš„æˆåŠŸ ï¼ˆæ€§èƒ½æå‡ï¼‰
                if s.get('type') == 'arch_expansion' and s.get('result_type') == 'success':
                    case_info = f"- Score Change: {s.get('improvement', 0):.3f} (improved)"
                    if 'config_diff' in s:
                        case_info += f"\n  Config Changes: {json.dumps(s['config_diff'], indent=2)}"
                    if 'is_pareto_improvement' in s and s['is_pareto_improvement']:
                        case_info += f"\n  âœ¨ Joined Pareto Front!"
                    if 'performance' in s:
                        perf = s['performance']
                        case_info += f"\n  Performance: Acc={perf.get('accuracy', 0):.1f}%, Mem={perf.get('memory', 0):.1f}MB, Lat={perf.get('latency', 0):.1f}ms"
                    case_info += f"\n  Parent Score: {s.get('parent_score', 0):.3f} â†’ Current Score: {s.get('current_score', 0):.3f}"
                    success_cases.append(case_info)
            
            if success_cases:
                success_feedback = "\n".join(success_cases)
        
        
        # å½“å‰ä¼šè¯çš„çº¦æŸè¿ååé¦ˆ ï¼ˆè¿™ä¸ªå¾ˆé‡è¦ï¼ï¼‰
        session_constraint_feedback = "None"
        if context.get('session_failures'):
            feedback_items = []
            for failure in context['session_failures']:
                item = f"Attempt {failure['attempt']}: Candidate {failure.get('candidate_id', '?')} - {failure.get('failure_type', 'Unknown')}"
                # æ˜¾ç¤ºå†…å­˜ä¿¡æ¯
                if failure.get('estimated_memory'):
                    item += f"\n  - Memory: {failure['estimated_memory']}MB"
                
                # æ˜¾ç¤ºé‡åŒ–æ¨¡å¼
                if failure.get('quant_mode'):
                    item += f"\n  - Quantization: {failure['quant_mode']}"
                
                # æ˜¾ç¤ºå…·ä½“åŸå› 
                if failure.get('failure_reason'):
                    item += f"\n  - Reason: {failure['failure_reason']}"

                # æ˜¾ç¤ºé…ç½®æ‘˜è¦
                if failure.get('config'):
                    config = failure['config']
                    stages = len(config.get('stages', []))
                    total_blocks = sum(len(stage.get('blocks', [])) for stage in config.get('stages', []))
                    item += f"\n  - Architecture: {stages} stages, {total_blocks} blocks"
                    item += f"\n  - Quant mode: {config.get('quant_mode', 'none')}"
                    # å°†configå‹ç¼©åˆ°ä¸€è¡Œï¼Œç§»é™¤æ¢è¡Œç¬¦å’Œå¤šä½™ç©ºæ ¼
                    config_str = json.dumps(config, separators=(',', ':'))  # ä½¿ç”¨æœ€å°åŒ–çš„JSONæ ¼å¼
                    item += f"\n  - Config: {config_str}"
                
                # æ˜¾ç¤ºå»ºè®®
                if failure.get('suggestions'):
                    item += f"\n  - Fix: {failure['suggestions']}"

                feedback_items.append(item)

            session_constraint_feedback = "\n".join(feedback_items)
        
        # æ–°å¢ï¼šæ¥è‡ªéªŒè¯å™¨çš„å³æ—¶çº¦æŸåé¦ˆ
        immediate_constraint_feedback = context.get('constraint_feedback', "None")

        # è¯»å–JSONæ–‡ä»¶
        with open('/root/tinyml/arch_files/model_mmact.json', 'r') as f:
            data = json.load(f)

        # æå–æ¶æ„ä¿¡æ¯
        arch_info = []
        for model in data['model_comparisons']:
            info = f"{model['model_description']}: Memory={model['peak_memory_mb']}MB Latency={model['inference_latency_ms']}ms "
            info = info + f"Config: {json.dumps(model['config'], separators=(',', ':'))}\n"
            arch_info.append(info)

        # å°†ä¿¡æ¯è¿æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç”¨ç©ºæ ¼åˆ†éš”
        basic_conv_info = " ".join(arch_info)

        # æ·»åŠ çº¦æŸæ¡ä»¶ï¼ˆä¿æŒä¸å˜ï¼‰
        constraints = {
            'max_peak_memory': float(self.search_space['constraints']['max_peak_memory']) / 1e6,
            'max_latency': float(self.search_space['constraints']['max_latency'])
        }
        # print(f"constraints: {constraints}")
        max_peak_memory = str(constraints['max_peak_memory'])
        quant_max_memory = str(constraints['max_peak_memory'] * 4)  # é‡åŒ–åå†…å­˜é™åˆ¶ä¸º4å€
        expected_memory = str(constraints['max_peak_memory'] * 0.75)  # æœŸæœ›å†…å­˜ä¸º3å€
        expected_quant_memory = str(constraints['max_peak_memory'] * 3)  # æœŸæœ›å†…å­˜ä¸º4å€
        # åˆ é™¤äº†paretoå‰æ²¿ï¼Œåªä¿ç•™çˆ¶èŠ‚ç‚¹ï¼ŒæˆåŠŸä¿®æ”¹çš„æç¤º
        prompt = """
            You are a neural architecture optimization expert. 
            Based on the search context, generate 5 DIFFERENT architecture candidates that improves upon the parent architecture.

            **CRITICAL CONSTRAINT VIOLATIONS TO AVOID:**
            {immediate_constraint_feedback}

            **Current Session Failed Attempts:**
            {session_constraint_feedback}
            
            **Constraints:**
            {constraints}

            **Search Space:**
            {search_space}

            **Recent Successful Modifications (Performance Improvements):**
            These modifications resulted in higher scores compared to their parent architectures:
            {success_feedback}

            **Recent Failed Modifications (Performance Degradations):**
            These modifications resulted in lower scores compared to their parent architectures:
            {failure_feedback}

            **Parent Architecture Performance:**
            {parent_info}

            **Dataset Information:**
            - Name: {dataset_name}
            - Input Shape: (batch_size, {channels}, {time_steps})
            - Number of Classes: {num_classes}
            - Description: {description}

            **Conv Type:**
            1. DWSepConvBlock: Depthwise separable convolution (Depthwise + Pointwise) structure with skip connection support.
            2. MBConvBlock: Inverted residual structure (expansion convolution + Depthwise + SE module + Pointwise) with skip connection support.
            3. DpConvBlock: Pure depthwise convolution (Depthwise + Pointwise) structure without SE module or skip connections.
            4. SeSepConvBlock: Depthwise separable convolution with SE module (Depthwise + SE + Pointwise) structure.
            5. SeDpConvBlock: Depthwise convolution with SE module (Depthwise + SE) structure without Pointwise convolution.
            
            **Basic information of a single conv block:**
            (The memory and delay of these individual blocks are only for reference, 
            and can be further reduced or increased by modifying parameters such as `has_se`, `expansion`, `skip_connection`, `activation`, etc)
            {basic_conv_info}
            
            **Important Notes:**
            - If has_se is set to False, then se_ratios will be considered as 0, and vice versa. Conversely, if Has_se is set to True, then se_ratios must be greater than 0, and the same holds true in reverse.
            - In the search space, "DWSepConv" and "MBConv" both refer to "DWSepConv1D" and "MBConv1D", but when you generate the configuration, you should only write "DWSepConv" and "MBConv" according to the instructions in the search space.
            - "MBConv" is only different from "DWSeqConv" when expansion > 1, otherwise they are the same block.
            - If the type of a convolution block is "SeDpConv", then the `in_channels` and `out_channels` of this convolution block must be equal. This means that: - The `out_channels` of the previous convolution block must be equal to both the `in_channels` and `out_channels` of "SeDpConv".
            - If "SeDpConv" is a block in the first stage, its `channels` should be equal to `input_channels`, otherwise an error will be reported.
            - Even if stage 1 may achieve better results, you can try a neural network architecture with only one stage.
            - In addition to modifying the architecture, you can also choose to apply quantization to the model.
            - Quantization modes available: {quantization_modes} (e.g., "none" means no quantization, "static" applies static quantization, "qat" applies QAT quantization).
            - Among them, you should note that "static" or "qat" quantization will reduce the memory to 1/4 of its original size(qat will also reduct the memory to 1/4), so you can use model architectures within (4 * {max_peak_memory} = {quant_max_memory})MB.
            - However, quantization is likely to lead to a decrease in model performance, so you need to be cautious!
            - Finally, if the memory limit is not exceeded, do not use quantization!
            
            **Memory-Aware Architecture Strategy:**
            (You should generate an architecture that fits the expected model as much as possible.)
            if max_peak_memory = 15 MB:
            - Tier 1 (No quantization): Target 12-15 MB models for best accuracy
            - Tier 2 (Static quantization or QAT quantization): Target 45-60 MB models (will become ~12-15MB after 4x compression)
  
            - Current exploration focus: {tier_suggestion}

            **Quantization Trade-off Guidance:**
            - Static or QAT quantization reduces memory by 4x but may decrease accuracy by 5-15% (sometimes over 25%).
            - A {quant_max_memory}MB model with 85% accuracy â†’ After quantization: {max_peak_memory}MB with ~75% accuracy
            - A {max_peak_memory}MB model with 70% accuracy â†’ No quantization needed: {max_peak_memory}MB with 70% accuracy
            - But you should be aware that quantization can sometimes lead to a performance drop of over 25%, so you should not only explore quantization but also non quantization.

            **Important Rule**
            - Generate 5 DIFFERENT architectures with varying memory usage.
            - Include both quantized and non-quantized options.
            - Each of the five candidate architectures can only have one category different from the parent architecture. These categories include: add, delete, and modify.
            - Add: Add a new stage or block.
            - Delete: Remove an existing stage or block.
            - Modify: Change parameters of an existing stage or block (e.g., quant_mode, kernel_size, expansion, channels, has_se, etc.)
            - You can only make one type of change (add, delete, or modify) per candidate architecture.
            - Ensure that the generated architectures are unique and not duplicates of each other or the parent architecture.
            - Note that regardless of the type of addition, deletion, or modification, only one step of change can be made each time, which means adding, deleting, or modifying one.
            - But if there is no parent node or the parent node is none, these five model architectures can be generated freely, without having to follow the rule of only making one change at a time. But these five architectures should conform to *Memory-Aware Architecture Strategy* as much as possible.
            
            **Task:**
            You need to design 5 different model architecture capable of processing a diverse range of time series data for human activity recognition (HAR), And under the constraint conditions, the higher the accuracy of this model, the better. 

            **Requirement:**
            1. Strictly follow the given search space and constraints.
            2. Return the schema configuration in JSON format.
            3. Includes complete definitions of stages and blocks.
            4. If there are failure cases and the reason for failure is exceeding limits, then immediately reduce the parameters or reduce the block. Conversely, increase them.

            **Return format example:**
            {{
                "candidates": [
                    {{
                        "input_channels": {example_channels},  
                        "num_classes": {example_classes},
                        "quant_mode": "...",
                        "stages": [...]
                    }},
                    {{
                        "input_channels": {example_channels},  
                        "num_classes": {example_classes},
                        "quant_mode": "...",
                        "stages": [...]
                    }},
                    {{
                        "input_channels": {example_channels},  
                        "num_classes": {example_classes},
                        "quant_mode": "...",
                        "stages": [...]
                    }},
                    {{
                        "input_channels": {example_channels},  
                        "num_classes": {example_classes},
                        "quant_mode": "...",
                        "stages": [...]
                    }},
                    {{
                        "input_channels": {example_channels},  
                        "num_classes": {example_classes},
                        "quant_mode": "...",
                        "stages": [...]
                    }}
                ]
            }}""".format(
                    immediate_constraint_feedback=immediate_constraint_feedback,
                    session_constraint_feedback=session_constraint_feedback,
                    constraints=json.dumps(constraints, indent=2),
                    search_space=json.dumps(self.search_space['search_space'], separators=(',', ':')),
                    quantization_modes=json.dumps(self.search_space['search_space']['quantization_modes']),
                    success_feedback=success_feedback,
                    failure_feedback=failure_feedback,
                    parent_info=parent_info,
                    dataset_name=context['dataset_name'],
                    channels=dataset_info['channels'],
                    time_steps=dataset_info['time_steps'],
                    num_classes=dataset_info['num_classes'],
                    description=dataset_info['description'],
                    basic_conv_info=basic_conv_info,
                    max_peak_memory=max_peak_memory,
                    quant_max_memory=quant_max_memory,
                    expected_memory=expected_memory,
                    expected_quant_memory=expected_quant_memory,
                    tier_suggestion=f"Models should ideally be within {expected_memory}-{max_peak_memory} MB without quantization, or {expected_quant_memory}-{quant_max_memory} MB with static quantization.",
                    example_channels=dataset_info['channels'],
                    example_classes=dataset_info['num_classes'],
                    example_constraints=json.dumps(constraints, indent=2),
                    parent_performance=parent_info
                )
        
        print(f"ç”Ÿæˆçš„æç¤º:\n{prompt}\n")

        return prompt
    
    def _parse_multiple_candidates_response(self, response: str) -> Optional[List[CandidateModel]]:
        """è§£æLLMå“åº”ä¸ºå¤šä¸ªCandidateModel"""
        try:
            # æå–JSONé…ç½®
            json_match = re.search(r'```json(.*?)```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
            else:
                json_match = re.search(r'```(.*?)```', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1).strip()
                else:
                    return None
            
            # è§£æJSON
            response_data = json.loads(json_str)
            candidates_data = response_data.get('candidates', [])
            
            if len(candidates_data) != 5:
                print(f"âŒ æœŸæœ›5ä¸ªå€™é€‰ï¼Œä½†å¾—åˆ°äº†{len(candidates_data)}ä¸ª")

            candidates = []
            for i, candidate_data in enumerate(candidates_data, 1):
                try:
                    if not all(k in candidate_data for k in ['stages', 'input_channels', 'num_classes']):
                        print(f"âŒ å€™é€‰{i}ç¼ºå°‘å¿…è¦å­—æ®µ")
                        continue
                    
                    candidate = CandidateModel(config=candidate_data)
                    candidate.metadata['quantization_mode'] = candidate_data.get('quant_mode', 'none')
                    candidates.append(candidate)
                    
                except Exception as e:
                    print(f"âŒ è§£æå€™é€‰{i}å¤±è´¥: {str(e)}")
                    continue
            
            print(f"âœ… æˆåŠŸè§£æ{len(candidates)}/5ä¸ªå€™é€‰æ¶æ„")
            return candidates
            
        except Exception as e:
            print(f"è§£æLLMå“åº”å¤±è´¥: {str(e)}")
            return []
        
    def _review_and_select_candidate(self, candidates: List[CandidateModel], 
                                dataset_name: str, attempt: int,
                                session_failures: List[Dict],
                                all_valid_candidates: List[Dict] = None) -> tuple[Optional['CandidateModel'], List[Dict]]:
        """è¯„å®¡5ä¸ªå€™é€‰å¹¶é€‰æ‹©æœ€ä½³çš„ä¸€ä¸ªï¼Œå¢åŠ å»é‡é€»è¾‘
        è¿”å›: (æœ€ä½³å€™é€‰, æœ¬æ¬¡å°è¯•ä¸­æ‰€æœ‰é€šè¿‡éªŒè¯çš„å€™é€‰åˆ—è¡¨)
        """
        
        if not candidates:
            return None, []
        
        print(f"\nğŸ” å¼€å§‹è¯„å®¡{len(candidates)}ä¸ªå€™é€‰æ¶æ„...")
        
        valid_candidates = []
        validation_details = []  # è®°å½•æ¯ä¸ªå€™é€‰çš„éªŒè¯è¯¦æƒ…
        current_valid_candidates = []  # æœ¬æ¬¡å°è¯•ä¸­é€šè¿‡éªŒè¯çš„å€™é€‰ï¼ˆç”¨äºç´¯ç§¯ï¼‰

        # åˆå§‹åŒ– Zero-Cost ä»£ç†è¯„ä¼°å™¨
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        proxy_evaluator = ZeroCostProxies(device=device)
        
        # è·å–æ•°æ®é›†ä¿¡æ¯ç”¨äºè¾“å…¥å½¢çŠ¶
        dataset_info = self.dataset_info[dataset_name]
        input_shape = (dataset_info['channels'], dataset_info['time_steps'])

        # è·å–å†…å­˜çº¦æŸå’ŒæœŸæœ›å€¼
        max_peak_memory = float(self.search_space['constraints'].get('max_peak_memory', float('inf'))) / 1e6
        non_quant_expect_min = max_peak_memory * 0.75
        quant_expect_min = max_peak_memory * 3.0
        min_memory_threshold = max_peak_memory * 0.4  # æ–°å¢ï¼šå†…å­˜è¿‡å°çš„é˜ˆå€¼
        
        for i, candidate in enumerate(candidates, 1):
            try:
                print(f"\n--- è¯„ä¼°å€™é€‰ ç¬¬ {i} ä¸ª Candidateã€‚---")
                
                # åŸºç¡€çº¦æŸéªŒè¯
                is_valid, failure_reason, suggestions = self._validate_candidate(candidate, dataset_name)
                
                # è®°å½•éªŒè¯è¯¦æƒ…ï¼ˆæ— è®ºæˆåŠŸå¤±è´¥ï¼‰
                validation_detail = {
                    'candidate_id': i,
                    'is_valid': is_valid,
                    'failure_reason': failure_reason if not is_valid else None,
                    'suggestions': suggestions if not is_valid else None
                }

                if not is_valid:
                    print(f"âŒ å€™é€‰{i}çº¦æŸéªŒè¯å¤±è´¥: {failure_reason}")
                    validation_details.append(validation_detail)
                    # è®°å½•è¯¦ç»†çš„å¤±è´¥ä¿¡æ¯åˆ° session_failures
                    failure_info = {
                        'attempt': attempt + 1,
                        'failure_type': 'constraint_violation',
                        'candidate_id': i,
                        'config': candidate.config,
                        'estimated_memory': candidate.metadata.get('estimated_total_size_MB', 'unknown'),
                        'quant_mode': candidate.config.get('quant_mode', 'none'),
                        'failure_reason': failure_reason,
                        'suggestions': suggestions,
                        'violation_types': []
                    }
                    # åˆ†æå…·ä½“çš„è¿åç±»å‹
                    if 'memory' in failure_reason.lower() or 'exceeding' in failure_reason.lower():
                        failure_info['violation_types'].append('memory_constraint')
                    if 'latency' in failure_reason.lower():
                        failure_info['violation_types'].append('latency_constraint')

                    session_failures.append(failure_info)
                    continue

                # æ£€æŸ¥æ˜¯å¦é‡å¤
                if self._is_duplicate(candidate):
                    print(f"âŒ å€™é€‰{i}é‡å¤ï¼Œè·³è¿‡")
                    validation_detail['is_duplicate'] = True
                    validation_details.append(validation_detail)
                    # è®°å½•é‡å¤çš„æ¶æ„ä¿¡æ¯åˆ° session_failures
                    duplicate_info = {
                        'attempt': attempt + 1,  # ä¿®æ­£ï¼šä½¿ç”¨å½“å‰ attempt
                        'failure_type': 'duplicate_candidate',
                        'candidate_id': i,
                        'config': candidate.config,
                        'estimated_memory': candidate.metadata.get('estimated_total_size_MB', 'unknown'),
                        'quant_mode': candidate.config.get('quant_mode', 'none'),
                        'suggestion': 'This architecture already exists in the search space. Generate a different configuration.'
                    }
                    session_failures.append(duplicate_info)
                    continue
                
                # è®¡ç®—æœ‰æ•ˆå†…å­˜å’Œå†…å­˜åˆ†æ•°
                dataset_info = self.dataset_info[dataset_name]
                memory_usage = calculate_memory_usage(
                    candidate.build_model(),
                    input_size=(64, dataset_info['channels'], dataset_info['time_steps']),
                    device='cpu'
                )
                
                original_memory = memory_usage['total_memory_MB']
                quant_mode = candidate.config.get('quant_mode', 'none')
                
                # è®¡ç®—æœ‰æ•ˆå†…å­˜ï¼ˆç”¨äºæ¯”è¾ƒï¼‰
                if quant_mode == 'static' or quant_mode == 'qat':
                    effective_memory = original_memory / 4  # é‡åŒ–åçš„ å®é™…å†…å­˜
                    expect_min = non_quant_expect_min  # æœŸæœ›çš„æœ€ç»ˆå†…å­˜
                    # å†…å­˜åˆ†æ•°ï¼šåŸå§‹å†…å­˜è¶Šæ¥è¿‘ quant_expect_min è¶Šå¥½
                    memory_score = self._calculate_memory_score(original_memory, quant_expect_min, max_peak_memory * 4)
                    memory_type = f"é‡åŒ–æ¨¡å‹ ({original_memory:.1f}MB -> {effective_memory:.1f}MB)"
                else:
                    effective_memory = original_memory
                    expect_min = non_quant_expect_min
                    # å†…å­˜åˆ†æ•°ï¼šå†…å­˜è¶Šæ¥è¿‘ expect_max è¶Šå¥½
                    memory_score = self._calculate_memory_score(original_memory, non_quant_expect_min, max_peak_memory)
                    memory_type = f"éé‡åŒ–æ¨¡å‹ ({effective_memory:.1f}MB)"
                
                print(f"ğŸ’¾ {memory_type}, å†…å­˜åˆ†æ•°: {memory_score:.3f}")
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœŸæœ›å†…å­˜
                meets_expectation = effective_memory >= expect_min * 0.9  # å…è®¸10%çš„å®¹å·®
                min_standard = True
                # æ–°å¢é€»è¾‘ï¼šæ£€æŸ¥å†…å­˜æ˜¯å¦è¿‡å°
                if effective_memory < min_memory_threshold:
                    print(f"âš ï¸ å€™é€‰{i}å†…å­˜è¿‡å°ï¼Œä»… {effective_memory:.1f}MBï¼Œä½äºé˜ˆå€¼ {min_memory_threshold:.1f}MB")
                    session_failures.append({
                        'attempt': attempt + 1,
                        'failure_type': 'memory_too_small',
                        'candidate_id': i,
                        'config': candidate.config,
                        'estimated_memory': effective_memory,
                        'quant_mode': quant_mode,
                        'failure_reason': f"Memory too small: {effective_memory:.1f}MB (threshold: {min_memory_threshold:.1f}MB)",
                        'suggestions': f"You should generate a schema that is within the expected memory range {non_quant_expect_min}-{max_peak_memory}.- Increase the model size by adding more blocks, stages, or channels.\n- Add stages or use other Conv block such as DWSepConv\MBConv\DpConv\SeSepConv.\n- The model architecture using static or qat should be larger than that without quantification to ensure that the memory is within the expected range."
                    })
                    min_standard = False
                    # continue  # è·³è¿‡æ­¤å€™é€‰

                # ğŸ”¥ ä½¿ç”¨Zero-Costä»£ç†æ–¹æ³•è¯„ä¼°æ¶æ„è´¨é‡
                print(f"ğŸ§  ä½¿ç”¨Zero-Costä»£ç†æ–¹æ³•è¯„ä¼°å€™é€‰{i}...")
                try:
                    model = candidate.build_model()
                    proxy_results = proxy_evaluator.compute_composite_score(
                        model=model,
                        input_shape=input_shape,
                        batch_size=16,
                        weights={
                            'grad_norm': 0.3,   # æ¢¯åº¦èŒƒæ•°æƒé‡
                            'synflow': 0.3,     # SynFlowæƒé‡  
                            'zen': 0.2,         # Zen-NASæƒé‡
                            'zico': 0.2         # ZiCoæƒé‡
                        }
                    )
                    
                    proxy_score = proxy_results['composite_score']
                    raw_scores = proxy_results['raw_scores']
                    
                    print(f"ğŸ“Š {memory_type}")
                    print(f"   Zero-Costä»£ç†åˆ†æ•°: {proxy_score:.4f}")
                    print(f"   - GradNorm: {raw_scores['grad_norm']:.3f}")
                    print(f"   - SynFlow: {raw_scores['synflow']:.3f}")  
                    print(f"   - Zen-NAS: {raw_scores['zen']:.3f}")
                    print(f"   - ZiCo: {raw_scores['zico']:.3f}")
                    
                except Exception as e:
                    print(f"âš ï¸ Zero-Costä»£ç†æ–¹æ³•è¯„ä¼°å¤±è´¥: {e}")
                    proxy_score = 0.1  # ç»™ä¸€ä¸ªè¾ƒä½çš„é»˜è®¤åˆ†æ•°
                    raw_scores = {'grad_norm': 0, 'synflow': 0, 'zen': 0, 'zico': 0}
            
                candidate_info = {
                    'candidate': candidate,
                    'proxy_score': proxy_score,  # æ›¿ä»£memory_score
                    'raw_proxy_scores': raw_scores,
                    'memory_score': memory_score,
                    'effective_memory': effective_memory,
                    'original_memory': original_memory,
                    'meets_expectation': meets_expectation,
                    'quant_mode': quant_mode,
                    'min_standard': min_standard
                }
                
                valid_candidates.append(candidate_info)
                current_valid_candidates.append(candidate_info)  # æ·»åŠ åˆ°æœ¬æ¬¡éªŒè¯é€šè¿‡çš„åˆ—è¡¨
                validation_details.append({
                    'candidate_id': i,
                    'is_valid': True,
                    'proxy_score': proxy_score,
                    'memory_score': memory_score,
                    'effective_memory': effective_memory,
                    'meets_expectation': meets_expectation,
                    'min_standard': min_standard
                })
                print(f"âœ… å€™é€‰{i}é€šè¿‡éªŒè¯ï¼ŒæœŸæœ›è¾¾æˆ: {meets_expectation}")
                
            except Exception as e:
                print(f"âŒ å€™é€‰{i}è¯„ä¼°å¤±è´¥: {str(e)}")
                validation_details.append({
                    'candidate_id': i,
                    'is_valid': False,
                    'failure_reason': f"è¯„ä¼°å¼‚å¸¸: {str(e)}",
                    'suggestions': "æ£€æŸ¥æ¶æ„é…ç½®æ˜¯å¦æ­£ç¡®"
                })
                continue
        # æ£€æŸ¥é€šè¿‡éªŒè¯çš„å€™é€‰æ•°é‡
        # è¿™ä¸ªæ£€éªŒä¸èƒ½ä»…ä»…é€šè¿‡lenå‡½æ•°ï¼Œè¿˜è¦æ£€æŸ¥ min_standard
        # valid_count = len(valid_candidates)
        valid_count = sum(1 for v in valid_candidates if v['min_standard'])
        total_count = len(candidates)
        pass_rate = valid_count / total_count if total_count > 0 else 0
        
        print(f"\nğŸ“Š éªŒè¯ç»“æœç»Ÿè®¡:")
        print(f"   æ€»å€™é€‰æ•°: {total_count}")
        print(f"   é€šè¿‡éªŒè¯: {valid_count}")
        print(f"   é€šè¿‡ç‡: {pass_rate:.1%}")

        # è´¨é‡æ§åˆ¶ï¼š è‡³å°‘éœ€è¦3ä¸ªå€™é€‰é€šè¿‡éªŒè¯ï¼ˆ 60%é€šè¿‡ç‡ ï¼‰
        if valid_count < self.valid_threshold:
            print(f"âŒ è´¨é‡æ§åˆ¶å¤±è´¥: åªæœ‰{valid_count}/5ä¸ªå€™é€‰é€šè¿‡éªŒè¯ï¼Œä½äºæœ€ä½è¦æ±‚(3ä¸ª)")
        
            # æ„å»ºè¯¦ç»†çš„å¤±è´¥æŠ¥å‘Š
            failure_report = self._build_validation_failure_report(validation_details, attempt)
            # ç¡®ä¿ failure_report ä¸­çš„ valid_count æ­£ç¡®
            self.current_valid_candidates = current_valid_candidates
            failure_report['valid_count'] = valid_count
            failure_report['pass_rate'] = pass_rate
            
            # æŠ›å‡ºç‰¹æ®Šå¼‚å¸¸ï¼ŒåŒ…å«å¤±è´¥è¯¦æƒ…ï¼Œ è¿™å°†è¢«ä¸Šå±‚æ•è·å¹¶æ·»åŠ åˆ° session_failures
            raise CandidateQualityException(failure_report)

        if not valid_candidates:
            print("âŒ æ²¡æœ‰å€™é€‰é€šè¿‡åŸºç¡€éªŒè¯")
            return None, current_valid_candidates
        
        # é€‰æ‹©ç­–ç•¥ï¼šä¼˜å…ˆé€‰æ‹©å†…å­˜åˆ†æ•°æœ€é«˜çš„
        valid_candidates.sort(key=lambda x: x['memory_score'], reverse=True)
        
        selected = valid_candidates[0]
        print(f"\nğŸ¯ é€‰æ‹©æœ€ä½³å€™é€‰:")
        print(f"   ç­–ç•¥: {selected['candidate'].metadata.get('strategy', 'Unknown')}")
        print(f"   é‡åŒ–æ¨¡å¼: {selected['quant_mode']}")
        print(f"   åŸå§‹å†…å­˜: {selected['original_memory']:.1f}MB")
        print(f"   æœ‰æ•ˆå†…å­˜: {selected['effective_memory']:.1f}MB") 
        print(f"   å†…å­˜åˆ†æ•°: {selected['memory_score']:.3f}")
        print(f"   æœŸæœ›è¾¾æˆ: {selected['meets_expectation']}")
        
        # æ‰“å°æ‰€æœ‰å€™é€‰çš„æ¯”è¾ƒ
        print(f"\nğŸ“Š æ‰€æœ‰å€™é€‰æ¯”è¾ƒ:")
        for i, cand in enumerate(valid_candidates, 1):
            status = "âœ… é€‰ä¸­" if i == 1 else "  "
            print(f"{status} å€™é€‰{i}: {cand['effective_memory']:.1f}MB (åˆ†æ•°: {cand['memory_score']:.3f})")
        
        return selected['candidate'], current_valid_candidates
    
    def _is_duplicate(self, candidate: CandidateModel) -> bool:
        """æ£€æŸ¥å€™é€‰æ¶æ„æ˜¯å¦ä¸å·²æœ‰æ¶æ„é‡å¤"""
        if self.mcts_graph is None:
            return False

        for node in self.mcts_graph.nodes.values():
            if node.candidate and node.candidate.config == candidate.config:
                print(f"âš ï¸ æ¶æ„é‡å¤: {json.dumps(candidate.config, indent=2)}")
                return True
        return False
    
    def _calculate_memory_score(self, memory: float, target_min: float, target_max: float) -> float:
        """è®¡ç®—å†…å­˜åˆ†æ•°"""
        if memory > target_max:
            return -1.0
        elif memory < target_min * 0.5:
            return 0.1
        elif memory < target_min:
            return 0.3 + 0.4 * (memory / target_min)
        else:
            return 0.7 + 0.3 * (memory / target_max)
        
    def _build_validation_failure_report(self, validation_details: List[Dict], attempt: int) -> Dict:
        """æ„å»ºéªŒè¯å¤±è´¥æŠ¥å‘Š"""
        failed_candidates = [v for v in validation_details if not v['is_valid']]
        valid_candidates = [v for v in validation_details if v['is_valid']]
        
        # åˆ†æå¤±è´¥åŸå› 
        failure_reasons = {}
        for failed in failed_candidates:
            reason = failed.get('failure_reason', 'Unknown')
            if 'memory' in reason.lower() or 'exceeding' in reason.lower():
                failure_type = 'memory_constraint'
            elif 'latency' in reason.lower():
                failure_type = 'latency_constraint'
            elif 'è§£æ' in reason or 'parsing' in reason.lower():
                failure_type = 'parsing_error'
            else:
                failure_type = 'other_constraint'
            
            if failure_type not in failure_reasons:
                failure_reasons[failure_type] = []
            failure_reasons[failure_type].append({
                'candidate_id': failed['candidate_id'],
                'reason': reason,
                'suggestions': failed.get('suggestions', '')
            })
        
        # åˆ†ææœ‰æ•ˆå€™é€‰çš„å†…å­˜åˆ†å¸ƒ
        memory_analysis = ""
        if valid_candidates:
            memories = [v.get('effective_memory', 0) for v in valid_candidates]
            avg_memory = sum(memories) / len(memories)
            max_memory = max(memories)
            min_memory = min(memories)
            memory_analysis = f"æœ‰æ•ˆå€™é€‰å†…å­˜èŒƒå›´: {min_memory:.1f}MB - {max_memory:.1f}MB (å¹³å‡: {avg_memory:.1f}MB)"
        
        report = {
            'attempt': attempt,
            'total_candidates': len(validation_details),
            'valid_count': len(valid_candidates),
            'pass_rate': len(valid_candidates) / len(validation_details),
            'failure_reasons': failure_reasons,
            'memory_analysis': memory_analysis,
            'detailed_failures': failed_candidates,
            'improvement_suggestions': self._generate_improvement_suggestions(failure_reasons, valid_candidates)
        }
        
        return report
    
    def _generate_improvement_suggestions(self, failure_reasons: Dict, valid_candidates: List[Dict]) -> str:
        """æ ¹æ®å¤±è´¥åŸå› ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if 'memory_constraint' in failure_reasons:
            memory_failures = len(failure_reasons['memory_constraint'])
            suggestions.append(f"ğŸ”§ Memory constraint violation ({memory_failures} candidates): architecture size needs to be reduced")
            suggestions.append("   - Reduce the number of stages (most effective)")
            suggestions.append("   - Reduce the number of blocks in each stage")
            suggestions.append("   - Reduce the number of channels")
            suggestions.append("   - Replace MBConv with DWSeqConv or DpConv or SeSepConv or SeDpConv")
        
        if 'latency_constraint' in failure_reasons:
            latency_failures = len(failure_reasons['latency_constraint'])
            suggestions.append(f"â±ï¸ Delay constraint violation ({latency_failures} candidates): Need to optimize computational efficiency")
            suggestions.append("   - Reduce kernelsize")
            suggestions.append("   - Reduce the expansion ratio")
            suggestions.append("   - Use fewer blocks")
        
        # å¦‚æœæœ‰æœ‰æ•ˆå€™é€‰ï¼Œåˆ†æå…¶ç‰¹å¾
        if valid_candidates:
            avg_memory = sum(v.get('effective_memory', 0) for v in valid_candidates) / len(valid_candidates)
            suggestions.append(f"âœ… Effective candidate average memory: {avg_memory:.1f}MB")
            suggestions.append("   - Can refer to the architecture features of valid candidates")
            suggestions.append("   - Appropriately increase the architecture within the effective range to improve memory utilization")
        
        if len(suggestions) == 0:
            suggestions.append("ğŸ” Please check the architecture configuration format and constraints")
        
        return "\n".join(suggestions)

    def _record_successful_modification(self, parent_node: ArchitectureNode, 
                                     candidate: CandidateModel, attempt: int):
        """è®°å½•æˆåŠŸçš„ä¿®æ”¹åˆ°çˆ¶èŠ‚ç‚¹"""
        modification = {
            'type': 'llm_expansion',
            'config': candidate.config,
            'attempt': attempt,
            'timestamp': time.time()
        }

        parent_node.record_modification(modification, success=True)
    
    def _record_failed_modification(self, parent_node: ArchitectureNode, 
                                  candidate: CandidateModel, failure_reason: str, 
                                  suggestions: str, attempt: int):
        """è®°å½•å¤±è´¥çš„ä¿®æ”¹åˆ°çˆ¶èŠ‚ç‚¹"""
        modification = {
            'type': 'llm_expansion',
            'config': candidate.config,
            'failure_reason': failure_reason,
            'suggestions': suggestions,
            'attempt': attempt,
            'timestamp': time.time()
        }
        # print(f"\n=== å¤±è´¥çš„ modification å†…å®¹ ===")
        # print(json.dumps(modification, indent=2, default=str))
        # print("=" * 40)
        parent_node.record_modification(modification, success=False)