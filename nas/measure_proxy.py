import openai  # æˆ–å…¶ä»– LLM API
import sys
import json5
import json
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List
import re
sys.path.append(str(Path(__file__).resolve().parent.parent))  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
from utils import initialize_llm, calculate_memory_usage  # ä¿®æ”¹å¯¼å…¥è·¯å¾„
# ä»configså¯¼å…¥æç¤ºæ¨¡æ¿
from configs import get_search_space, get_llm_config, get_tnas_search_space
# å¯¼å…¥æ¨¡å‹å’Œçº¦æŸéªŒè¯ç›¸å…³æ¨¡å—
from models.candidate_models import CandidateModel
from data import get_multitask_dataloaders, get_dataset_info
from training import MultiTaskTrainer, SingleTaskTrainer
import numpy as np
import os
from datetime import datetime
import pytz
from Proxyless import ZeroCostProxies, RZNASProxies 
import torch
import copy
import itertools
import multiprocessing as mp
from multiprocessing import Pool, Queue, Process, Manager
import time
import signal
from scipy.stats import kendalltau, spearmanr

import random

def set_random_seed(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ä»¥ç¡®ä¿å¯å¤ç°æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

llm_config = get_llm_config()
# search_space = get_search_space()
search_space = get_tnas_search_space()

def _load_dataset_info(name):
    return get_dataset_info(name)

def test_model_worker(config, description, dataset_name, base_save_dir, gpu_id, result_queue):
    """
    å·¥ä½œè¿›ç¨‹å‡½æ•°ï¼Œåœ¨æŒ‡å®šçš„GPUä¸Šæµ‹è¯•æ¨¡å‹
    """
    try:
        # è®¾ç½®éšæœºç§å­ï¼ˆä½¿ç”¨gpu_idä½œä¸ºåç§»ä»¥ç¡®ä¿ä¸åŒGPUæœ‰ä¸åŒçš„ç§å­ï¼‰
        worker_seed = 42 + gpu_id
        set_random_seed(worker_seed)

        # è®¾ç½®å½“å‰è¿›ç¨‹ä½¿ç”¨çš„GPU
        torch.cuda.set_device(gpu_id)
        device = torch.device(f'cuda:{gpu_id}')
        
        print(f"ğŸš€ è¿›ç¨‹ {os.getpid()} åœ¨ GPU {gpu_id} ä¸Šæµ‹è¯•: {description}")
        
        # é‡æ–°åˆå§‹åŒ–æ•°æ®é›†å’Œè¯„ä¼°å™¨ï¼ˆæ¯ä¸ªè¿›ç¨‹éœ€è¦è‡ªå·±çš„å®ä¾‹ï¼‰
        dataset_info = _load_dataset_info(dataset_name)
        dataloaders = get_multitask_dataloaders('/root/tinyml/data')
        dataloader = dataloaders[dataset_name]
        proxy_evaluator = RZNASProxies(search_space, device=device)
        
        # æ„å»ºå€™é€‰æ¨¡å‹
        candidate = CandidateModel(config=config)
        model = candidate.build_model().to(device)
        
        # è®¡ç®—å†…å­˜ä½¿ç”¨
        memory_usage = calculate_memory_usage(
            model,
            input_size=(64, 6, 300),
            device='cuda'
        )
        total_memory_mb = memory_usage['total_memory_MB']
        
        # è®¡ç®—ä»£ç†åˆ†æ•°
        input_shape = (dataset_info['channels'], dataset_info['time_steps'])
        model_copy = copy.deepcopy(model).to(device)
        proxy_results = proxy_evaluator.compute_composite_score(
            model=model_copy,
            input_shape=input_shape,
            batch_size=64,
            quant_mode='none'
        )
        
        proxy_score = proxy_results['composite_score']
        raw_scores = proxy_results['raw_scores']

        print(f"ğŸ“Š GPU {gpu_id} ä»£ç†åˆ†æ•°è®¡ç®—å®Œæˆ: {description} - Proxy: {proxy_score:.4f}")
        # print(f"{"-"*50}")
        # print(f"   Zero-Costä»£ç†åˆ†æ•°: {proxy_score:.4f}")
        # print(f"   - GradNorm: {raw_scores['grad_norm']:.3f}")
        # print(f"   - Grasp: {raw_scores['grasp']:.3f}")
        # print(f"   - Zen-NAS: {raw_scores['zen']:.3f}")
        # print(f"   - Synflow: {raw_scores['synflow']:.3f}")
        # print(f"   - ZiCo: {raw_scores['zico']:.3f}")
        
        # è®­ç»ƒæ¨¡å‹
        trainer = SingleTaskTrainer(model, dataloader, device=device) # åœ¨åˆå§‹æ—¶ä¼ é€’è®¾å¤‡
        model_save_dir = os.path.join(base_save_dir, description.replace(" ", "_"))
        os.makedirs(model_save_dir, exist_ok=True)
        model_save_path = os.path.join(model_save_dir, "best_model.pth")

        print(f"ğŸ‹ï¸ GPU {gpu_id} å¼€å§‹è®­ç»ƒ: {description} (60 epochs)")
        best_acc, best_val_metrics, history, best_state = trainer.train(
            epochs=200, 
            save_path=model_save_path
        )
        
        # æµ‹è¯•å»¶è¿Ÿ
        latency_ms = candidate.measure_latency(device=device, dataset_names='UTD-MHAD')
        
        # å‡†å¤‡ç»“æœ
        result = {
            "description": description,
            "accuracy": best_acc,
            "val_accuracy": best_val_metrics['accuracy'] / 100,
            "latency": latency_ms,
            "peak_memory": total_memory_mb,
            "config": config,
            "proxy_scores": proxy_score,
            "raw_scores": raw_scores,
            "gpu_id": gpu_id,
            "status": "success"
        }
        
        # ä¿å­˜æ¨¡å‹é…ç½®
        config_save_path = os.path.join(model_save_dir, "model.json")
        model_data = {
            "config": config,
            "latency": latency_ms,
            "peak_memory": total_memory_mb,
            "accuracy": best_acc,
            "val_accuracy": result["val_accuracy"],
            "proxy_scores": proxy_score,
            "raw_scores": raw_scores,
            "gpu_id": gpu_id
        }

        # ä¿®æ”¹ä¸ºï¼š
        with open(config_save_path, "w", encoding="utf-8") as f:
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
            def convert_numpy_types(obj):
                if isinstance(obj, (np.integer, np.floating)):
                    return float(obj) if isinstance(obj, np.floating) else int(obj)
                elif isinstance(obj, np.bool_):
                    return bool(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, dict):
                    return {k: convert_numpy_types(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy_types(item) for item in obj]
                return obj
            
            converted_data = convert_numpy_types(model_data)
            json.dump(converted_data, f, indent=2, ensure_ascii=False)
        
        result_queue.put(result)
        print(f"âœ… GPU {gpu_id} å®Œæˆ: {description} - Acc: {best_acc:.2f}%, Proxy: {proxy_score:.4f}, Latency: {latency_ms:.2f}ms")
        
    except Exception as e:
        error_result = {
            "description": description,
            "config": config,
            "status": "failed",
            "error": str(e),
            "gpu_id": gpu_id
        }
        result_queue.put(error_result)
        print(f"âŒ GPU {gpu_id} å¤±è´¥: {description} - {e}")
        import traceback
        traceback.print_exc()

def gpu_worker(gpu_id, task_queue, result_queue, dataset_name, base_save_dir):
    """
    GPUå·¥ä½œè¿›ç¨‹ï¼Œä»ä»»åŠ¡é˜Ÿåˆ—è·å–ä»»åŠ¡å¹¶æ‰§è¡Œ
    """
    print(f"ğŸ”„ GPUå·¥ä½œè¿›ç¨‹ {os.getpid()} å¯åŠ¨ï¼Œä½¿ç”¨ GPU {gpu_id}")
    
    while True:
        try:
            # è·å–ä»»åŠ¡
            task = task_queue.get(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
            if task is None:  # ç»“æŸä¿¡å·
                print(f"ğŸ›‘ GPU {gpu_id} æ”¶åˆ°ç»“æŸä¿¡å·")
                break
                
            config, description = task
            test_model_worker(config, description, dataset_name, base_save_dir, gpu_id, result_queue)
            
        except Exception as e:
            print(f"âŒ GPU {gpu_id} å·¥ä½œè¿›ç¨‹é”™è¯¯: {e}")
            break

def create_gpu_processes(num_gpus, task_queue, result_queue, dataset_name, base_save_dir):
    """
    åˆ›å»ºGPUå·¥ä½œè¿›ç¨‹
    """
    processes = []
    for gpu_id in range(num_gpus):
        p = Process(
            target=gpu_worker,
            args=(gpu_id, task_queue, result_queue, dataset_name, base_save_dir)
        )
        p.daemon = True
        p.start()
        processes.append(p)
        time.sleep(1)  # é¿å…åŒæ—¶å¯åŠ¨æ‰€æœ‰è¿›ç¨‹
    
    return processes

def generate_stratified_configurations(seed=42):
    """ä½¿ç”¨åˆ†å±‚æŠ½æ ·ç­–ç•¥ç”Ÿæˆé…ç½®"""
    # è®¾ç½®éšæœºç§å­
    random.seed(seed)
    np.random.seed(seed)

    configurations = []
    seen_configs = set()  # ç”¨äºè·Ÿè¸ªå·²ç»ç”Ÿæˆçš„é…ç½®
    
    # å®šä¹‰æœç´¢å‚æ•°
    conv_types_options = ["DWSepConv", "MBConv", "DpConv", "SeSepConv", "SeDpConv"]
    channels_options = [8, 16, 24]
    has_se_options = [True, False]
    skip_connection_options = [True, False]
    expansions_options = [1, 2, 3]
    
    # åˆ†å±‚æŠ½æ ·ç­–ç•¥ï¼š40ä¸ªå•stage + 280ä¸ªåŒstage = 320ä¸ªé…ç½®
    target_count = 320
    single_stage_count = 40
    double_stage_count = 280
    
    # ç”Ÿæˆå•stageé…ç½® (50ä¸ª)
    print("ç”Ÿæˆå•stageé…ç½®...")
    single_stage_configs = generate_single_stage_configs(conv_types_options, channels_options, 
                                                        has_se_options, skip_connection_options, 
                                                        expansions_options, single_stage_count, seen_configs, seed)
    
    # ç”ŸæˆåŒstageé…ç½® (50ä¸ª)
    print("ç”ŸæˆåŒstageé…ç½®...")
    double_stage_configs = generate_double_stage_configs(conv_types_options, channels_options, 
                                                        has_se_options, skip_connection_options, 
                                                        expansions_options, double_stage_count, seen_configs, seed)
    
    configurations.extend(single_stage_configs)
    configurations.extend(double_stage_configs)
    
    return configurations

def generate_single_stage_configs(conv_types, channels, has_se_opts, skip_conn_opts, expansions, count, seen_configs, seed):
    """ç”Ÿæˆå•stageé…ç½®"""
    # è®¾ç½®éšæœºçŠ¶æ€
    random_state = random.getstate()
    np_state = np.random.get_state()
    
    random.seed(seed)
    np.random.seed(seed)

    configs = []
    conv_type_counts = {conv: 0 for conv in conv_types}
    target_per_type = count // len(conv_types)
    max_attempts = 1000  # é˜²æ­¢æ— é™å¾ªç¯
    
    for conv_type in conv_types:
        attempts = 0
        while conv_type_counts[conv_type] < target_per_type and attempts < max_attempts:
            attempts += 1

            # ä¸ºæ¯ç§å·ç§¯ç±»å‹ç”Ÿæˆä»£è¡¨æ€§é…ç½®
            if conv_type == "MBConv":
                expansion = np.random.choice([2, 3])
                has_se = np.random.choice(has_se_opts)
                skip_conn = np.random.choice(skip_conn_opts)
                channel = np.random.choice(channels)
            elif conv_type == "DWSepConv":
                expansion = 1
                has_se = np.random.choice(has_se_opts)
                skip_conn = np.random.choice(skip_conn_opts)
                channel = np.random.choice(channels)
            elif conv_type == "DpConv":
                expansion = 1
                has_se = False
                skip_conn = False
                channel = np.random.choice(channels)
            elif conv_type == "SeSepConv":
                expansion = 1
                has_se = np.random.choice(has_se_opts)
                skip_conn = False
                channel = np.random.choice(channels)
            elif conv_type == "SeDpConv":
                expansion = 1
                has_se = np.random.choice(has_se_opts)
                skip_conn = False
                channel = 6  # SeDpConvç¬¬ä¸€å±‚é€šé“å¿…é¡»ä¸º6
            
            # å¤„ç†SEæ¯”ä¾‹
            se_ratio = 0.25 if has_se else 0
            
            block_config = {
                "type": conv_type,
                "kernel_size": 3,
                "expansion": expansion,
                "has_se": has_se,
                "se_ratios": se_ratio,
                "skip_connection": skip_conn,
                "stride": 1,
                "activation": "ReLU6"
            }
            
            stage_config = {
                "blocks": [block_config],
                "channels": channel
            }
            
            config = {
                "input_channels": 6,
                "num_classes": 27,
                "quant_mode": "none",
                "stages": [stage_config],
                "constraints": search_space['constraints']
            }

            # ç”Ÿæˆé…ç½®çš„å”¯ä¸€æ ‡è¯†ç¬¦
            config_hash = get_config_hash(config)

            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
            if config_hash in seen_configs:
                continue

            seen_configs.add(config_hash)
            
            description = f"S1_{conv_type}_C{channel}"
            if has_se:
                description += f"_SE{se_ratio}"
            if skip_conn:
                description += "_Skip"
            if expansion > 1:
                description += f"_Exp{expansion}"
            
            configs.append((config, f"Model_{len(configs):03d}_{description}"))
            conv_type_counts[conv_type] += 1
    
    # æ¢å¤éšæœºçŠ¶æ€
    random.setstate(random_state)
    np.random.set_state(np_state)
    
    return configs

def generate_double_stage_configs(conv_types, channels, has_se_opts, skip_conn_opts, expansions, count, seen_configs, seed):
    """ç”ŸæˆåŒstageé…ç½®"""
    # è®¾ç½®éšæœºçŠ¶æ€
    random_state = random.getstate()
    np_state = np.random.get_state()
    
    random.seed(seed)
    np.random.seed(seed)

    configs = []
    max_attempts = 2000  # é˜²æ­¢æ— é™å¾ªç¯
    
    # ç¡®ä¿è¦†ç›–æ‰€æœ‰æœ‰æ„ä¹‰çš„ç»„åˆ
    combinations_to_test = [
        # (stage1_type, stage2_type) ç»„åˆ
        ("DWSepConv", "DWSepConv"),
        ("DWSepConv", "MBConv"),
        ("DWSepConv", "SeSepConv"),
        ("MBConv", "DWSepConv"),
        ("MBConv", "MBConv"),
        ("MBConv", "SeSepConv"),
        ("SeSepConv", "DWSepConv"),
        ("SeSepConv", "MBConv"),
        ("SeSepConv", "SeSepConv"),
        ("DpConv", "DWSepConv"),  # ç®€å•+å¤æ‚
        ("DpConv", "SeSepConv"),
        ("DpConv", "MBConv"),
        ("SeDpConv", "MBConv"),   # SeDpConvåªèƒ½åœ¨ç¬¬ä¸€å±‚
        ("SeDpConv", "DWSepConv"),
    ]
    
    # æ¯ç§ç»„åˆæµ‹è¯•å‡ ä¸ªé…ç½®
    per_combination = max(1, count // len(combinations_to_test))
    
    for stage1_type, stage2_type in combinations_to_test:
        attempts = 0
        while attempts < 10:  # æ¯ç§ç»„åˆå°è¯•ç”Ÿæˆå‡ ä¸ªé…ç½®
            attempts += 1

            # ç”Ÿæˆ stage1 é…ç½®
            stage1_config = generate_stage_config(stage1_type, channels, has_se_opts, skip_conn_opts, expansions, 1)
            
            # ç”Ÿæˆ stage2 é…ç½®ï¼Œ è€ƒè™‘é€šé“è¿ç»­æ€§
            stage2_channel = np.random.choice(channels)
            stage2_config = generate_stage_config(stage2_type, [stage2_channel], has_se_opts, skip_conn_opts, expansions, 2)
            
            # å¤„ç† SeDpConv çš„ç‰¹æ®Šçº¦æŸ
            if stage1_type == "SeDpConv":
                stage1_config["channels"] = 6  # ç¬¬ä¸€å±‚ SeDpConv é€šé“å¿…é¡»ä¸º6
            
            config = {
                "input_channels": 6,
                "num_classes": 27,
                "quant_mode": "none",
                "stages": [stage1_config, stage2_config],
                "constraints": search_space['constraints']
            }
            
            description = f"S1{stage1_type}C{stage1_config['channels']}_S2{stage2_type}C{stage2_config['channels']}"
            if stage1_config["blocks"][0]["has_se"]:
                description += f"_S1SE{stage1_config['blocks'][0]['se_ratios']}"
            if stage2_config["blocks"][0]["has_se"]:
                description += f"_S2SE{stage2_config['blocks'][0]['se_ratios']}"
            if stage1_config["blocks"][0]["skip_connection"]:
                description += "_S1Skip"
            if stage2_config["blocks"][0]["skip_connection"]:
                description += "_S2Skip"
            
            configs.append((config, f"Model_{len(configs) + 50:03d}_{description}"))
    
    # å¦‚æœè¿˜æœ‰å‰©ä½™ä½ç½®ï¼Œéšæœºç”Ÿæˆä¸€äº›é…ç½®
    # å¦‚æœè¿˜æœ‰å‰©ä½™ä½ç½®ï¼Œéšæœºç”Ÿæˆä¸€äº›é…ç½®
    attempts = 0
    while len(configs) < count and attempts < max_attempts:
        attempts += 1

        stage1_type = np.random.choice(conv_types)
        stage2_type = np.random.choice(conv_types)
        
        stage1_config = generate_stage_config(stage1_type, channels, has_se_opts, skip_conn_opts, expansions, 1)
        stage2_config = generate_stage_config(stage2_type, channels, has_se_opts, skip_conn_opts, expansions, 2)
        
        if stage1_type == "SeDpConv":
            stage1_config["channels"] = 6
        
        config = {
            "input_channels": 6,
            "num_classes": 27,
            "quant_mode": "none",
            "stages": [stage1_config, stage2_config],
            "constraints": search_space['constraints']
        }
        
        config_hash = get_config_hash(config)
        if config_hash in seen_configs:
            continue
            
        seen_configs.add(config_hash)

        description = f"S1{stage1_type}C{stage1_config['channels']}_S2{stage2_type}C{stage2_config['channels']}"
        configs.append((config, f"Model_{len(configs) + 50:03d}_{description}"))
    
    # æ¢å¤éšæœºçŠ¶æ€
    random.setstate(random_state)
    np.random.set_state(np_state)

    return configs

def get_config_hash(config):
    """ç”Ÿæˆé…ç½®çš„å”¯ä¸€å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡"""
    # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„é…ç½®è¡¨ç¤ºç”¨äºå“ˆå¸Œ
    hash_parts = []
    
    for i, stage in enumerate(config['stages']):
        block = stage['blocks'][0]
        stage_hash = f"S{i}_{block['type']}_C{stage['channels']}_E{block['expansion']}"
        stage_hash += f"_SE{block['has_se']}_{block['se_ratios']}"
        stage_hash += f"_Skip{block['skip_connection']}"
        hash_parts.append(stage_hash)
    
    return "|".join(hash_parts)

def generate_stage_config(conv_type, channels, has_se_opts, skip_conn_opts, expansions, stage_idx):
    """ç”Ÿæˆå•ä¸ªstageçš„é…ç½®"""
    channel = np.random.choice(channels)
    
    if conv_type == "MBConv":
        expansion = np.random.choice([2, 3])
        has_se = np.random.choice(has_se_opts)
        skip_conn = np.random.choice(skip_conn_opts) if stage_idx > 0 else np.random.choice(skip_conn_opts)
    elif conv_type == "DWSepConv":
        expansion = 1
        has_se = np.random.choice(has_se_opts)
        skip_conn = np.random.choice(skip_conn_opts) if stage_idx > 0 else np.random.choice(skip_conn_opts)
    elif conv_type == "DpConv":
        expansion = 1
        has_se = False
        skip_conn = False
    elif conv_type == "SeSepConv":
        expansion = 1
        has_se = np.random.choice(has_se_opts)
        skip_conn = False
    elif conv_type == "SeDpConv":
        expansion = 1
        has_se = np.random.choice(has_se_opts)
        skip_conn = False
        if stage_idx == 1:  # ç¬¬äºŒå±‚SeDpConvéœ€è¦ç‰¹æ®Šå¤„ç†
            channel = channels[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªé€šé“é€‰é¡¹
    
    se_ratio = 0.25 if has_se else 0
    
    block_config = {
        "type": conv_type,
        "kernel_size": 3,
        "expansion": expansion,
        "has_se": has_se,
        "se_ratios": se_ratio,
        "skip_connection": skip_conn,
        "stride": 1,
        "activation": "ReLU6"
    }
    
    return {
        "blocks": [block_config],
        "channels": channel
    }

# 3. åˆ†æTop-Kå‘½ä¸­ç‡
def calculate_top_k_hit_rate(proxy_scores, accuracies, k_values=[1, 3, 5, 10]):
    """è®¡ç®—Top-Kå‘½ä¸­ç‡"""
    n_models = len(proxy_scores)
    hit_rates = {}
    
    for k in k_values:
        if k > n_models:
            continue
            
        # æŒ‰proxy scoreé€‰æ‹©Top-K
        top_k_proxy = np.argsort(proxy_scores)[-k:][::-1]  # æœ€é«˜çš„kä¸ª
        
        # æŒ‰accuracyé€‰æ‹©çœŸæ­£çš„Top-K
        true_top_k = np.argsort(accuracies)[-k:][::-1]  # æœ€é«˜çš„kä¸ª
        
        # è®¡ç®—å‘½ä¸­ç‡
        hit_count = len(set(top_k_proxy) & set(true_top_k))
        hit_rate = hit_count / k
        hit_rates[k] = hit_rate
        
        print(f"  Top-{k} å‘½ä¸­ç‡: {hit_rate:.3f} ({hit_count}/{k})")
    
    return hit_rates

def analyze_results(results, base_save_dir):
    """åˆ†æç»“æœ"""
    successful_results = [r for r in results if r.get('status') == 'success']
    failed_results = [r for r in results if r.get('status') == 'failed']
    
    print(f"\n=== æœ€ç»ˆæµ‹è¯•ç»“æœ ===")
    print(f"æˆåŠŸæµ‹è¯•: {len(successful_results)} ä¸ªæ¨¡å‹")
    print(f"å¤±è´¥æµ‹è¯•: {len(failed_results)} ä¸ªæ¨¡å‹")
    
    # æŒ‰GPUç»Ÿè®¡
    gpu_stats = {}
    for result in successful_results:
        gpu_id = result.get('gpu_id', -1)
        if gpu_id not in gpu_stats:
            gpu_stats[gpu_id] = 0
        gpu_stats[gpu_id] += 1
    
    print(f"GPUä½¿ç”¨ç»Ÿè®¡: {gpu_stats}")

    if not successful_results:
        print("âš ï¸ æ²¡æœ‰æˆåŠŸçš„ç»“æœå¯ä¾›åˆ†æ")
        return
    
    proxy_scores = [r['proxy_scores'] for r in successful_results]
    accuracies = [r['accuracy'] for r in successful_results]
    descriptions = [r['description'] for r in successful_results]
    
    # æå– raw_scores çš„æ‰€æœ‰é”®ï¼ˆå‡è®¾æ‰€æœ‰ç»“æœçš„ raw_scores é”®ç›¸åŒï¼‰
    if successful_results:
        all_raw_score_keys = list(successful_results[0].get('raw_scores', {}).keys())
    else:
        all_raw_score_keys = []
    print(f"ä»£ç†æŒ‡æ ‡åŒ…æ‹¬: {all_raw_score_keys}")
    # æå–raw_scoresä¸­çš„å„ä¸ªæŒ‡æ ‡
    # raw_score_metrics = {}
    # for metric_name in ['grad_norm', 'flops', 'zen', 'memory_utilization', 'depth_width_balance']:
    #     raw_score_metrics[metric_name] = [
    #         r['raw_scores'].get(metric_name, 0) for r in successful_results
    #     ]
    raw_score_metrics = {key: [] for key in all_raw_score_keys}
    for key in all_raw_score_keys:
        for result in successful_results:
            raw_score_metrics[key].append(result.get('raw_scores', {}).get(key, 0))

    # è®¡ç®—ç»¼åˆproxy scoreçš„ç›¸å…³ç³»æ•°
    composite_correlation = np.corrcoef(proxy_scores, accuracies)[0, 1]
    print(f"\nğŸ“ˆ ç›¸å…³ç³»æ•°åˆ†æ:")
    print(f"Proxy Score å’Œå‡†ç¡®ç‡çš„ç›¸å…³ç³»æ•°: {composite_correlation:.4f}")

    # 2. è®¡ç®—æ’åºä¸€è‡´æ€§æŒ‡æ ‡ - Kendall Tau
    
    
    # æŒ‰proxy scoreæ’åº
    proxy_ranking = np.argsort(proxy_scores)[::-1]  # ä»é«˜åˆ°ä½
    accuracy_ranking = np.argsort(accuracies)[::-1]  # ä»é«˜åˆ°ä½
    
    # Kendall Tau ç›¸å…³ç³»æ•°
    kendall_tau, kendall_p = kendalltau(proxy_ranking, accuracy_ranking)
    print(f"Kendall Tau æ’åºä¸€è‡´æ€§: {kendall_tau:.4f} (p={kendall_p:.4f})")
    
    # Spearman ç§©ç›¸å…³ç³»æ•°
    spearman_rho, spearman_p = spearmanr(proxy_ranking, accuracy_ranking)
    print(f"Spearman ç§©ç›¸å…³ç³»æ•°: {spearman_rho:.4f} (p={spearman_p:.4f})")

    print(f"\nğŸ¯ Top-K å‘½ä¸­ç‡åˆ†æ:")
    top_k_hit_rates = calculate_top_k_hit_rate(proxy_scores, accuracies)

    # 4. åˆ†ææ’åå‰10%çš„æ¨¡å‹
    n_top = max(1, len(proxy_scores) // 10)  # å‰10%
    top_proxy_indices = np.argsort(proxy_scores)[-n_top:][::-1]
    top_accuracy_indices = np.argsort(accuracies)[-n_top:][::-1]

    print(f"\nğŸ† å‰10%æ¨¡å‹åˆ†æ (n={n_top}):")
    print("æŒ‰Proxy Scoreæ’åå‰10%çš„æ¨¡å‹:")
    for i, idx in enumerate(top_proxy_indices):
        print(f"  {i+1}. {descriptions[idx]} - Proxy: {proxy_scores[idx]:.4f}, Acc: {accuracies[idx]:.2f}%")
    
    print("\næŒ‰çœŸå®å‡†ç¡®ç‡æ’åå‰10%çš„æ¨¡å‹:")
    for i, idx in enumerate(top_accuracy_indices):
        print(f"  {i+1}. {descriptions[idx]} - Acc: {accuracies[idx]:.2f}%, Proxy: {proxy_scores[idx]:.4f}")

    
    # 5. è®¡ç®—æ¯ä¸ªraw scoreæŒ‡æ ‡çš„æ’åºä¸€è‡´æ€§
    print(f"\nğŸ” å„ä»£ç†æŒ‡æ ‡çš„æ’åºä¸€è‡´æ€§:")
    correlation_results = {}
    for metric_name, metric_values in raw_score_metrics.items():
        try:
            if len(metric_values) > 1 and np.std(metric_values) > 0:  # ç¡®ä¿æœ‰æ–¹å·®
                # Pearsonç›¸å…³ç³»æ•°
                pearson_corr = np.corrcoef(metric_values, accuracies)[0, 1]
                
                # Kendall Tau
                metric_ranking = np.argsort(metric_values)[::-1]
                kendall_tau_metric, _ = kendalltau(metric_ranking, accuracy_ranking)

                correlation_results[metric_name] = {
                    'pearson': pearson_corr,
                    'kendall_tau': kendall_tau_metric
                }
                print(f"  - {metric_name}: Pearson={pearson_corr:.4f}, Kendall Tau={kendall_tau_metric:.4f}")
            else:
                correlation_results[metric_name] = None
                print(f"  - {metric_name}: æ•°æ®ä¸è¶³æˆ–æ–¹å·®ä¸ºé›¶")
        except Exception as e:
            correlation_results[metric_name] = None
            print(f"  - {metric_name} è®¡ç®—ç›¸å…³ç³»æ•°å¤±è´¥: {e}")

    # ä¿å­˜åˆ†æç»“æœ
    analysis = {
        "total_tested": len(results),
        "successful": len(successful_results),
        "failed": len(failed_results),
        "gpu_statistics": gpu_stats,
        "correlation": {
            "pearson": composite_correlation,
            "kendall_tau": kendall_tau,
            "spearman_rho": spearman_rho,
            "kendall_p_value": kendall_p,
            "spearman_p_value": spearman_p
        },
        "top_k_hit_rates": top_k_hit_rates,
        "top_10_percent": {
            "by_proxy": [descriptions[i] for i in top_proxy_indices],
            "by_accuracy": [descriptions[i] for i in top_accuracy_indices],
            "overlap": len(set(top_proxy_indices) & set(top_accuracy_indices)) / n_top
        },
        "proxy_scores": proxy_scores,
        "raw_scores_details": {
            metric: values for metric, values in raw_score_metrics.items()
        },
        "raw_scores_correlations": correlation_results,  # æ·»åŠ è¿™è¡Œ
        "accuracies": accuracies,
        "descriptions": descriptions,
        "results": results
    }
    
    analysis_path = os.path.join(base_save_dir, "analysis.json")

    # æ·»åŠ ç±»å‹è½¬æ¢å‡½æ•°
    def convert_numpy_types(obj):
        if isinstance(obj, (np.integer, np.floating)):
            return float(obj) if isinstance(obj, np.floating) else int(obj)
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {k: convert_numpy_types(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_numpy_types(item) for item in obj]
        return obj
    
    # è½¬æ¢numpyç±»å‹
    converted_analysis = convert_numpy_types(analysis)
    
    with open(analysis_path, "w", encoding="utf-8") as f:
        json.dump(converted_analysis, f, indent=2, ensure_ascii=False)

    # with open(analysis_path, "w", encoding="utf-8") as f:
    #     json.dump(analysis, f, indent=2, ensure_ascii=False)
    print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_path}")

# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":

    # è®¾ç½®å…¨å±€éšæœºç§å­
    set_random_seed(42)

    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹å¼
    mp.set_start_method('spawn', force=True)
    
    # è®¾ç½®ä¿¡å·å¤„ç†ï¼Œé¿å…é”®ç›˜ä¸­æ–­æ—¶å‡ºç°åƒµå°¸è¿›ç¨‹
    original_sigint = signal.signal(signal.SIGINT, signal.SIG_IGN)

    try:
        signal.signal(signal.SIGINT, original_sigint)

        dataset_name = 'UTD-MHAD'  # æ›¿æ¢ä¸ºå®é™…æ•°æ®é›†åç§°
        quant_mode = 'none'  # å¯é€‰ 'none', 'static', 'qat'

        try:
            # åˆå§‹åŒ– Zero-Cost ä»£ç†è¯„ä¼°å™¨
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            proxy_evaluator = RZNASProxies(search_space, device=device)
            dataset_info = _load_dataset_info(dataset_name)
            
            # åŠ è½½æ•°æ®é›†
            dataloaders = get_multitask_dataloaders('/root/tinyml/data')
            dataloader = dataloaders[dataset_name]

            # è®¾ç½®ä¿å­˜ç›®å½•
            save_dir = "/root/tinyml/weights/tinyml/proxy_validation"
            os.makedirs(save_dir, exist_ok=True)
            
            # è®¾ç½®ä¸­å›½æ ‡å‡†æ—¶é—´ï¼ˆUTC+8ï¼‰
            china_timezone = pytz.timezone("Asia/Shanghai")
            timestamp = datetime.now(china_timezone).strftime("%m-%d-%H-%M")
            base_save_dir = os.path.join(save_dir, timestamp)
            os.makedirs(base_save_dir, exist_ok=True)

            # ç”Ÿæˆæ‰€æœ‰è¦æµ‹è¯•çš„é…ç½®
            # configurations = generate_configurations()
            configurations = generate_stratified_configurations()
            print(f"ç”Ÿæˆäº† {len(configurations)} ä¸ªé…ç½®è¿›è¡Œæµ‹è¯•")
            print(f"å• stage é…ç½®: {len([c for c in configurations if len(c[0]['stages']) == 1])}")
            print(f"åŒ stage é…ç½®: {len([c for c in configurations if len(c[0]['stages']) == 2])}")

            # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—å’Œç»“æœé˜Ÿåˆ—
            manager = Manager()
            task_queue = manager.Queue()
            result_queue = manager.Queue()

            # å°†ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
            for config in configurations:
                task_queue.put(config)
            
            # æ·»åŠ ç»“æŸä¿¡å·
            num_gpus = 4  # ä½ æœ‰4ä¸ªGPU
            for _ in range(num_gpus):
                task_queue.put(None)
            
            # åˆ›å»ºGPUå·¥ä½œè¿›ç¨‹
            processes = create_gpu_processes(num_gpus, task_queue, result_queue, dataset_name, base_save_dir)

            results = []
            completed_count = 0
            total_tasks = len(configurations)

            try:
                while completed_count < total_tasks:
                    try:
                        result = result_queue.get(timeout=3600)  # 1å°æ—¶è¶…æ—¶
                        results.append(result)
                        completed_count += 1
                        
                        # å®æ—¶ä¿å­˜ç»“æœ
                        results_save_path = os.path.join(base_save_dir, "test_results.json")
                        # with open(results_save_path, "w", encoding="utf-8") as f:
                        #     json.dump(results, f, indent=2, ensure_ascii=False)
                        with open(results_save_path, "w", encoding="utf-8") as f:
                            def convert_numpy_types(obj):
                                if isinstance(obj, (np.integer, np.floating)):
                                    return float(obj) if isinstance(obj, np.floating) else int(obj)
                                elif isinstance(obj, np.bool_):
                                    return bool(obj)
                                elif isinstance(obj, np.ndarray):
                                    return obj.tolist()
                                elif isinstance(obj, dict):
                                    return {k: convert_numpy_types(v) for k, v in obj.items()}
                                elif isinstance(obj, list):
                                    return [convert_numpy_types(item) for item in obj]
                                return obj
                            
                            converted_results = convert_numpy_types(results)
                            json.dump(converted_results, f, indent=2, ensure_ascii=False)
            
                        # æ·»åŠ è¯¦ç»†çš„è¿›åº¦ä¿¡æ¯
                        progress_percent = completed_count / total_tasks * 100
                        remaining_tasks = total_tasks - completed_count
                        print(f"ğŸ“Š è¿›åº¦: {completed_count}/{total_tasks} ({progress_percent:.1f}%)")
                        print(f"  å‰©ä½™ä»»åŠ¡: {remaining_tasks}")

                        # æ˜¾ç¤ºæœ€è¿‘å®Œæˆçš„ä»»åŠ¡è¯¦æƒ…
                        if result.get('status') == 'success':
                            print(f"  æœ€æ–°å®Œæˆ: {result['description']}")
                            print(f"    å‡†ç¡®ç‡: {result['accuracy']:.2f}%, Proxy: {result['proxy_scores']:.4f}")
                        else:
                            print(f"  æœ€æ–°å¤±è´¥: {result['description']}")
                            print(f"    é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                        print("-" * 80)

                    except Exception as e:
                        print(f"âš ï¸ ç»“æœæ”¶é›†è¶…æ—¶æˆ–é”™è¯¯: {e}")
                        break
                        
            except KeyboardInterrupt:
                print("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œç­‰å¾…è¿›ç¨‹ç»“æŸ...")
            
            finally:
                # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ç»“æŸ
                for p in processes:
                    p.join(timeout=30)
                    if p.is_alive():
                        p.terminate()
                
                # åˆ†æç»“æœ
                analyze_results(results, base_save_dir)

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

    except KeyboardInterrupt:
        print("ğŸ›‘ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()        