import sys
import json
from pathlib import Path
from typing import Dict, Any, List
import numpy as np
import os
from datetime import datetime
import pytz
import torch
import copy
import multiprocessing as mp
from multiprocessing import Process, Manager
import time
import signal
from scipy.stats import kendalltau, spearmanr
import random
import logging
import queue  # éœ€è¦æ·»åŠ è¿™ä¸ªå¯¼å…¥
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).resolve().parent.parent))

from configs import get_tnas_search_space
from models.candidate_models import CandidateModel
from data import get_multitask_dataloaders, get_dataset_info
from training import SingleTaskTrainer
from GNNPredictor import ArchitectureDataset, ArchitectureEncoder
from nas import evaluate_quantized_model
from models import apply_configurable_static_quantization, get_quantization_option, fuse_QATmodel_modules

def set_random_seed(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ä»¥ç¡®ä¿å¯å¤ç°æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def setup_logger(gpu_id, log_dir):
    """ä¸ºæ¯ä¸ªGPUè¿›ç¨‹è®¾ç½®å•ç‹¬çš„æ—¥å¿—æ–‡ä»¶"""
    os.makedirs(log_dir, exist_ok=True)
    logger = logging.getLogger(f'GPU_{gpu_id}')
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    if logger.handlers:
        logger.handlers.clear()
    
    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(os.path.join(log_dir, f'output_{gpu_id}.log'))
    file_handler.setLevel(logging.INFO)
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # æ ¼å¼åŒ–
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

search_space = get_tnas_search_space()

def _load_dataset_info(name):
    return get_dataset_info(name)

def _prepare_model_for_qat(model, device):
    """ä¸ºQATé‡åŒ–æ„ŸçŸ¥è®­ç»ƒå‡†å¤‡æ¨¡å‹"""
    try:
        # è®¾ç½®QATé…ç½®
        model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')
        
        fuse_QATmodel_modules(model)
        # å‡†å¤‡QAT
        model.train()
        model.to(device)
        torch.quantization.prepare_qat(model, inplace=True)
        
        return model
        
    except Exception as e:
        print(f"âŒ QATå‡†å¤‡å¤±è´¥: {str(e)}")
        return model

def _apply_quantization_helper(model, dataloader, quant_mode: str, quantization_option: str = 'int8_per_channel'):
    """é‡åŒ–è¾…åŠ©æ–¹æ³•"""
    model_copy = copy.deepcopy(model)
    
    if quant_mode == 'static':
        quant_config = get_quantization_option(quantization_option)
        quantized_model = apply_configurable_static_quantization(
            model_copy,
            dataloader,
            precision=quant_config['precision'],
            backend=quant_config['backend']
        )
    elif quant_mode == 'qat':
        model_copy.eval()
        model_copy.to('cpu')
        quantized_model = torch.quantization.convert(model_copy, inplace=False)
    else:
        return model
    
    return quantized_model

def load_test_configurations(dataset_root_dir, encoder):
    """
    ä» ArchitectureDataset åŠ è½½æµ‹è¯•é›†é…ç½®
    """
    print("ğŸ“‚ åŠ è½½æµ‹è¯•é›†é…ç½®...")
    
    # åˆ›å»ºæµ‹è¯•é›†æ•°æ®é›†å®ä¾‹
    test_dataset = ArchitectureDataset(
        root_dir=dataset_root_dir,
        encoder=encoder,
        subset="test",
        seed=42  # å›ºå®šç§å­ç¡®ä¿å¯é‡å¤æ€§
    )
    
    configurations = []
    
    # éå†æµ‹è¯•é›†ï¼Œæå–é…ç½®å’Œå¯¹åº”çš„å‡†ç¡®ç‡
    for i in range(len(test_dataset)):
        config = test_dataset.architectures[i]
        original_accuracy = test_dataset.original_accuracies[i]
        quantized_accuracy = test_dataset.quantized_accuracies[i]
        qat_accuracy = test_dataset.qat_accuracies[i]
        
        # ç”Ÿæˆæè¿°ç¬¦
        description = f"Test_Model_{i:03d}"
        
        # æ·»åŠ é…ç½®ä¿¡æ¯
        configurations.append((
            config, 
            description,
            {
                "original_accuracy": original_accuracy,
                "quantized_accuracy": quantized_accuracy,
                "qat_accuracy": qat_accuracy
            }
        ))
    
    print(f"âœ… ä»æµ‹è¯•é›†åŠ è½½äº† {len(configurations)} ä¸ªé…ç½®")
    return configurations

def train_qat_model(model, dataloader, device, save_path, logger, epochs=5):
    """è®­ç»ƒQATæ¨¡å‹"""
    try:
        logger.info("ğŸ‹ï¸ å¼€å§‹ QAT é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ")
        
        # å‡†å¤‡ QAT æ¨¡å‹
        qat_model = _prepare_model_for_qat(copy.deepcopy(model), device)
        
        # åˆ›å»º QAT è®­ç»ƒå™¨
        qat_trainer = SingleTaskTrainer(qat_model, dataloader, device=device, logger=logger)
        
        # è®­ç»ƒ QAT æ¨¡å‹
        best_acc, best_val_metrics, history, best_state = qat_trainer.train(
            epochs=epochs, save_path=save_path
        )
        
        logger.info(f"âœ… QAT è®­ç»ƒå®Œæˆ - Acc: {best_acc:.2f}%")
        return qat_model, best_acc, best_state
        
    except Exception as e:
        logger.error(f"âŒ QATè®­ç»ƒå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, 0.0, None

def test_model_worker(config, description, truth, dataset_name, base_save_dir, gpu_id, result_queue, logger, epochs=5):
    """
    å·¥ä½œè¿›ç¨‹å‡½æ•°ï¼Œåœ¨æŒ‡å®šçš„GPUä¸Šæµ‹è¯•æ¨¡å‹
    """
    try:
        # è®¾ç½®éšæœºç§å­
        worker_seed = 42 + gpu_id
        set_random_seed(worker_seed)

        # è®¾ç½®å½“å‰è¿›ç¨‹ä½¿ç”¨çš„GPU
        torch.cuda.set_device(gpu_id)
        device = torch.device(f'cuda:{gpu_id}')
        
        print(f"ğŸš€ è¿›ç¨‹ {os.getpid()} åœ¨ GPU {gpu_id} ä¸Šæµ‹è¯•: {description}")
        
        # é‡æ–°åˆå§‹åŒ–æ•°æ®é›†å’Œè¯„ä¼°å™¨
        dataset_info = _load_dataset_info(dataset_name)
        dataloaders = get_multitask_dataloaders('/root/tinyml/data')
        dataloader = dataloaders[dataset_name]
        
        # å‡†å¤‡ç»“æœ
        result = {
            "description": description,
            "times": {},
            "accuracies": {},
            # "val_accuracy": best_val_metrics['accuracy'] / 100,
            # "training_time": original_time,
            "config": config,
            # "true_accuracy": truth["original_accuracy"],
            "gpu_id": gpu_id,
            "status": "success"
        }

        # 1. è®­ç»ƒåŸå§‹æ¨¡å‹
        logger.info(f"ğŸ‹ï¸ å¼€å§‹è®­ç»ƒåŸå§‹æ¨¡å‹: {description} ({epochs} epochs)")
        # æ„å»ºå€™é€‰æ¨¡å‹
        candidate = CandidateModel(config=config)
        original_model  = candidate.build_model().to(device)
        
        trainer = SingleTaskTrainer(original_model , dataloader, device=device)
        model_save_dir = os.path.join(base_save_dir, description.replace(" ", "_"))
        os.makedirs(model_save_dir, exist_ok=True)
        original_model_save_path = os.path.join(model_save_dir, "best_model.pth")
        # model_save_path = os.path.join(model_save_dir, "best_model.pth")

        # è®­ç»ƒæ¨¡å‹å¹¶è®°å½•æ—¶é—´
        start_time = time.time()

        print(f"ğŸ‹ï¸ GPU {gpu_id} å¼€å§‹è®­ç»ƒ: {description} ({epochs} epochs)")
        best_acc, best_val_metrics, history, best_state = trainer.train(
            epochs=epochs, 
            save_path=original_model_save_path
        )
        
        original_time  = time.time() - start_time
        
        result["accuracies"]["original"] = best_acc
        result["times"]["original"] = original_time
        result["true_accuracy"] = truth["original_accuracy"]

        logger.info(f"âœ… åŸå§‹æ¨¡å‹è®­ç»ƒå®Œæˆ: Acc: {best_acc:.2f}%, Time: {original_time:.2f}s")
        
        # result_queue.put(result)
        # logger.info(f"âœ… åŸå§‹æ¨¡å‹è®­ç»ƒå®Œæˆ: Acc: {best_acc:.2f}%, Time: {original_time:.2f}s")
        
        # 2. é™æ€é‡åŒ–
        logger.info(f"ğŸ”§ å¼€å§‹é™æ€é‡åŒ–: {description}")
        static_quant_start = time.time()

        quantization_options = [
            ('int8_default', 'é»˜è®¤INT8é‡åŒ–'),
            ('int8_per_channel', 'é€é€šé“INT8é‡åŒ–'), 
            ('int8_reduce_range', 'å‡å°‘èŒƒå›´INT8é‡åŒ–'),
            ('int8_asymmetric', 'INT8éå¯¹ç§°é‡åŒ–'),
            ('int8_histogram', 'INT8ç›´æ–¹å›¾æ ¡å‡†'),
            ('int8_moving_avg', 'INT8ç§»åŠ¨å¹³å‡æ ¡å‡†')
        ]

        best_quant_accuracy = 0.0
        best_option_name = ""
        
        for option_name, option_desc in quantization_options:
            try:
                logger.info(f"ğŸ”¬ å°è¯• {option_desc} ({option_name})")
                quantized_model = _apply_quantization_helper(
                    original_model, dataloader, 'static', option_name
                )
                
                if quantized_model:
                    task_head = torch.nn.Linear(original_model.output_dim, 
                        len(dataloader['test'].dataset.classes)).to('cpu')
                    if best_state and 'head' in best_state:
                        task_head.load_state_dict(best_state['head'])
                    
                    quant_accuracy = evaluate_quantized_model(
                        quantized_model, dataloader, task_head, f"é™æ€é‡åŒ–æ¨¡å‹({option_name})"
                    )
                    
                    logger.info(f"ğŸ“Š {option_desc} ç»“æœ: å‡†ç¡®ç‡={quant_accuracy:.1f}%")
                    
                    if quant_accuracy > best_quant_accuracy:
                        best_quant_accuracy = quant_accuracy
                        best_option_name = option_name
                        
            except Exception as e:
                logger.error(f"âŒ {option_desc} å¤±è´¥: {str(e)}")
                continue
        
        static_quant_time = time.time() - static_quant_start
        result["accuracies"]["static_quant"] = best_quant_accuracy
        result["times"]["static_quant"] = static_quant_time
        result["true_quant_accuracy"] = truth["quantized_accuracy"]
        
        logger.info(f"âœ… é™æ€é‡åŒ–å®Œæˆ: Best Acc: {best_quant_accuracy:.2f}%, Time: {static_quant_time:.2f}s")

        # 3. QATè®­ç»ƒ
        logger.info(f"ğŸ”§ å¼€å§‹ QAT è®­ç»ƒ: {description}")
        qat_start_time = time.time()
        
        # åˆ›å»ºæ–°çš„æœªç»è®­ç»ƒçš„æ¨¡å‹ç”¨äºQAT
        candidate = CandidateModel(config=config)
        qat_model = candidate.build_model().to(device)
        
        qat_model_save_path = os.path.join(model_save_dir, "qat_best_model.pth")
        qat_model, qat_accuracy, qat_best_state = train_qat_model(
            qat_model, dataloader, device, qat_model_save_path, logger, epochs=epochs
        )
        
        if qat_model:
            # è½¬æ¢å’Œè¯„ä¼°QATé‡åŒ–æ¨¡å‹
            qat_model.eval()
            qat_model.to('cpu')
            quantized_qat_model = torch.quantization.convert(qat_model, inplace=False)
            
            task_head = torch.nn.Linear(original_model.output_dim, 
                len(dataloader['test'].dataset.classes)).to('cpu')
            if qat_best_state and 'head' in qat_best_state:
                task_head.load_state_dict(qat_best_state['head'])
            
            qat_quant_accuracy = evaluate_quantized_model(
                quantized_qat_model, dataloader, task_head, f"QATé‡åŒ–æ¨¡å‹"
            )
            
            qat_time = time.time() - qat_start_time
            result["accuracies"]["qat"] = qat_accuracy
            result["accuracies"]["qat_quant"] = qat_quant_accuracy
            result["times"]["qat"] = qat_time
            result["true_qat_accuracy"] = truth["qat_accuracy"]
            
            logger.info(f"âœ… QATå®Œæˆ: Train Acc: {qat_accuracy:.2f}%, Quant Acc: {qat_quant_accuracy:.2f}%, Time: {qat_time:.2f}s")

        # ä¿å­˜ç»“æœ
        config_save_path = os.path.join(model_save_dir, "model.json")
        with open(config_save_path, "w", encoding="utf-8") as f:
            json.dump(convert_numpy_types(result), f, indent=2, ensure_ascii=False)
        
        result_queue.put(result)
        logger.info(f"âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ: {description}")
        
    except Exception as e:
        error_result = {
            "description": description,
            "config": config,
            "status": "failed",
            "error": str(e),
            "gpu_id": gpu_id
        }
        result_queue.put(error_result)
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {description} - {e}")
        import traceback
        traceback.print_exc()

def gpu_worker(gpu_id, task_queue, result_queue, dataset_name, base_save_dir, log_dir, epochs=5):
    """
    GPU å·¥ä½œè¿›ç¨‹ï¼Œä»ä»»åŠ¡é˜Ÿåˆ—è·å–ä»»åŠ¡å¹¶æ‰§è¡Œ
    """
    logger = setup_logger(gpu_id, log_dir)
    logger.info(f"ğŸ”„ GPUå·¥ä½œè¿›ç¨‹ {os.getpid()} å¯åŠ¨ï¼Œä½¿ç”¨ GPU {gpu_id}")
    
    while True:
        try:
            # è·å–ä»»åŠ¡
            task = task_queue.get(timeout=180)  # 3åˆ†é’Ÿè¶…æ—¶
            if task is None:  # ç»“æŸä¿¡å·
                logger.info(f"ğŸ›‘ GPU {gpu_id} æ”¶åˆ°ç»“æŸä¿¡å·")
                break
                
            config, description, truth = task
            test_model_worker(config, description, truth, dataset_name, base_save_dir, gpu_id, result_queue, logger, epochs)
            
        except Exception as e:
            logger.error(f"âŒ GPU {gpu_id} å·¥ä½œè¿›ç¨‹é”™è¯¯: {e}")
            break

def create_gpu_processes(num_gpus, task_queue, result_queue, dataset_name, base_save_dir, log_dir, epochs=5):
    """
    åˆ›å»ºGPUå·¥ä½œè¿›ç¨‹
    """
    processes = []
    for gpu_id in range(num_gpus):
        p = Process(
            target=gpu_worker,
            args=(gpu_id, task_queue, result_queue, dataset_name, base_save_dir, log_dir, epochs)
        )
        p.daemon = True
        p.start()
        processes.append(p)
        time.sleep(1)  # é¿å…åŒæ—¶å¯åŠ¨æ‰€æœ‰è¿›ç¨‹
    
    return processes

def convert_numpy_types(obj):
    """è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
    if isinstance(obj, (np.integer, np.floating)):
        return float(obj) if isinstance(obj, np.floating) else int(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {k: convert_numpy_types(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    return obj

def calculate_top_k_hit_rate(predicted_scores, true_scores, k_values=[1, 3, 5, 10]):
    """è®¡ç®—Top-Kå‘½ä¸­ç‡"""
    n_models = len(predicted_scores)
    hit_rates = {}
    
    for k in k_values:
        if k > n_models:
            continue
            
        # æŒ‰ predicted score é€‰æ‹©Top-K
        top_k_predicted = np.argsort(predicted_scores)[-k:][::-1]
        
        # æŒ‰ true score é€‰æ‹©çœŸæ­£çš„ Top-K
        true_top_k = np.argsort(true_scores)[-k:][::-1]
        
        # è®¡ç®—å‘½ä¸­ç‡
        hit_count = len(set(top_k_predicted) & set(true_top_k))
        hit_rate = hit_count / k
        hit_rates[k] = hit_rate
        
        print(f"  Top-{k} å‘½ä¸­ç‡: {hit_rate:.3f} ({hit_count}/{k})")
    
    return hit_rates

def analyze_results(results, base_save_dir):
    """åˆ†æç»“æœ"""
    successful_results = [r for r in results if r.get('status') == 'success']
    failed_results = [r for r in results if r.get('status') == 'failed']


    print(f"\n=== æœ€ç»ˆæµ‹è¯•ç»“æœ ===")
    print(f"æˆåŠŸæµ‹è¯•: {len(successful_results)} ä¸ªæ¨¡å‹")
    print(f"å¤±è´¥æµ‹è¯•: {len(failed_results)} ä¸ªæ¨¡å‹")

    if not successful_results:
        print("âš ï¸ æ²¡æœ‰æˆåŠŸçš„ç»“æœå¯ä¾›åˆ†æ")
        return

    # æå–ç»“æœæ•°æ®
    original_accuracies = [r['accuracies']['original'] for r in successful_results]
    static_quant_accuracies = [r['accuracies']['static_quant'] for r in successful_results]
    qat_accuracies = [r['accuracies']['qat'] for r in successful_results]
    qat_quant_accuracies = [r['accuracies']['qat_quant'] for r in successful_results]
    
    true_original_accuracies = [r['true_accuracy'] for r in successful_results]
    true_quant_accuracies = [r['true_quant_accuracy'] for r in successful_results]
    true_qat_accuracies = [r['true_qat_accuracy'] for r in successful_results]
    
    # æå–æ—¶é—´æ•°æ®
    original_times = [r['times']['original'] for r in successful_results]
    static_quant_times = [r['times']['static_quant'] for r in successful_results]
    qat_times = [r['times']['qat'] for r in successful_results]

    descriptions = [r['description'] for r in successful_results]

    print(f"\nâ± å¹³å‡æ—¶é—´å¼€é”€:")
    print(f"  åŸå§‹æ¨¡å‹è®­ç»ƒ: {np.mean(original_times):.2f}s")
    print(f"  é™æ€é‡åŒ–: {np.mean(static_quant_times):.2f}s")
    print(f"  QATè®­ç»ƒ: {np.mean(qat_times):.2f}s")
    print(f"  æ€»æ—¶é—´: {np.mean(original_times) + np.mean(static_quant_times) + np.mean(qat_times):.2f}s")
    
    # æŒ‰GPUç»Ÿè®¡
    gpu_stats = {}
    for result in successful_results:
        gpu_id = result.get('gpu_id', -1)
        if gpu_id not in gpu_stats:
            gpu_stats[gpu_id] = 0
        gpu_stats[gpu_id] += 1
    
    print(f"GPUä½¿ç”¨ç»Ÿè®¡: {gpu_stats}")


    # è®¡ç®—ç›¸å…³ç³»æ•°
    print(f"\nğŸ“ˆ ç›¸å…³ç³»æ•°åˆ†æ:")
    
    def calculate_correlation(predicted, true, label):
        pearson_corr = np.corrcoef(predicted, true)[0, 1]
        predicted_ranking = np.argsort(predicted)[::-1]
        true_ranking = np.argsort(true)[::-1]
        
        kendall_tau, kendall_p = kendalltau(predicted_ranking, true_ranking)
        spearman_rho, spearman_p = spearmanr(predicted_ranking, true_ranking)
        
        print(f"{label}:")
        print(f"  Pearsonç›¸å…³ç³»æ•°: {pearson_corr:.4f}")
        print(f"  Kendall Tauæ’åºä¸€è‡´æ€§: {kendall_tau:.4f} (p={kendall_p:.4f})")
        print(f"  Spearmanç§©ç›¸å…³ç³»æ•°: {spearman_rho:.4f} (p={spearman_p:.4f})")
        
        return {
            "pearson": pearson_corr,
            "kendall_tau": kendall_tau,
            "spearman_rho": spearman_rho,
            "kendall_p_value": kendall_p,
            "spearman_p_value": spearman_p
        }
    
    print(f"\nğŸ“ˆ ç›¸å…³ç³»æ•°åˆ†æ:")
    
    # åŸå§‹æ¨¡å‹ç›¸å…³æ€§
    original_corr = calculate_correlation(original_accuracies, true_original_accuracies, "5è½®åŸå§‹æ¨¡å‹ vs 100è½®çœŸå®åŸå§‹æ¨¡å‹")
    
    # é™æ€é‡åŒ–ç›¸å…³æ€§
    static_quant_corr = calculate_correlation(static_quant_accuracies, true_quant_accuracies, "é™æ€é‡åŒ– vs çœŸå®é™æ€é‡åŒ–")
    
    # QATç›¸å…³æ€§
    # qat_corr = calculate_correlation(qat_accuracies, true_qat_accuracies, "5è½®QAT vs 100è½®çœŸå®QAT")
    qat_quant_corr = calculate_correlation(qat_quant_accuracies, true_qat_accuracies, "QATé‡åŒ– vs çœŸå®QAT")

    # Top-Kå‘½ä¸­ç‡åˆ†æ
    print(f"\nğŸ¯ Top-K å‘½ä¸­ç‡åˆ†æ:")

    print("åŸå§‹æ¨¡å‹:")
    original_top_k = calculate_top_k_hit_rate(original_accuracies, true_original_accuracies)
    
    print("é™æ€é‡åŒ–:")
    static_top_k = calculate_top_k_hit_rate(static_quant_accuracies, true_quant_accuracies)
    
    print("QAT:")
    qat_top_k = calculate_top_k_hit_rate(qat_accuracies, true_qat_accuracies)


    # ä¿å­˜åˆ†æç»“æœ
    analysis = {
        "total_tested": len(results),
        "successful": len(successful_results),
        "failed": len(failed_results),
        "gpu_statistics": gpu_stats,
        "correlation": {
            "original": original_corr,
            "static_quant": static_quant_corr,
            "qat_quant": qat_quant_corr
        },
        "top_k_hit_rates": {
            "original": original_top_k,
            "static_quant": static_top_k,
            "qat": qat_top_k
        },
        "average_times": {
            "original": np.mean(original_times),
            "static_quant": np.mean(static_quant_times),
            "qat": np.mean(qat_times),
            "total": np.mean(original_times) + np.mean(static_quant_times) + np.mean(qat_times)
        },
        "accuracies": {
            "original": original_accuracies,
            "static_quant": static_quant_accuracies,
            "qat": qat_accuracies,
            "qat_quant": qat_quant_accuracies,
            "true_original": true_original_accuracies,
            "true_quant": true_quant_accuracies,
            "true_qat": true_qat_accuracies
        },
        "times": {
            "original": original_times,
            "static_quant": static_quant_times,
            "qat": qat_times
        },
        "descriptions": descriptions,
        "results": results
    }
    
    analysis_path = os.path.join(base_save_dir, "analysis.json")
    with open(analysis_path, "w", encoding="utf-8") as f:
        converted_analysis = convert_numpy_types(analysis)
        json.dump(converted_analysis, f, indent=2, ensure_ascii=False)

    print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_path}")

if __name__ == "__main__":
    # è®¾ç½®å…¨å±€éšæœºç§å­
    set_random_seed(42)

    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹å¼
    mp.set_start_method('spawn', force=True)
    
    # è®¾ç½®ä¿¡å·å¤„ç†
    original_sigint = signal.signal(signal.SIGINT, signal.SIG_IGN)

    try:
        signal.signal(signal.SIGINT, original_sigint)

        dataset_name = 'MMAct'
        epochs = 20  # è®­ç»ƒ5ä¸ªepochs

        # åˆå§‹åŒ–ç¼–ç å™¨
        encoder = ArchitectureEncoder()
        
        # è®¾ç½®ä¿å­˜ç›®å½•
        save_dir = "/root/tinyml/weights/tinyml/epoch_comparison"
        os.makedirs(save_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­å›½æ ‡å‡†æ—¶é—´
        china_timezone = pytz.timezone("Asia/Shanghai")
        timestamp = datetime.now(china_timezone).strftime("%m-%d-%H-%M")
        base_save_dir = os.path.join(save_dir, f"{timestamp}")
        os.makedirs(base_save_dir, exist_ok=True)

        log_dir = os.path.join(base_save_dir, "logs")
        os.makedirs(log_dir, exist_ok=True)

        # ä»æµ‹è¯•é›†åŠ è½½é…ç½®
        dataset_root_dir = "/root/tinyml/GNNPredictor/arch_data/MMAct"
        configurations_with_truth = load_test_configurations(dataset_root_dir, encoder)
        
        print(f"ä»æµ‹è¯•é›†åŠ è½½äº† {len(configurations_with_truth)} ä¸ªé…ç½®")

        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—å’Œç»“æœé˜Ÿåˆ—
        manager = Manager()
        task_queue = manager.Queue()
        result_queue = manager.Queue()

        # å°†ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
        for config, description, truth in configurations_with_truth:
            task_queue.put((config, description, truth))
        
        # æ·»åŠ ç»“æŸä¿¡å·
        num_gpus = 4  # ä½¿ç”¨4ä¸ªGPU
        for _ in range(num_gpus):
            task_queue.put(None)
        
        # åˆ›å»º GPU å·¥ä½œè¿›ç¨‹
        processes = create_gpu_processes(num_gpus, task_queue, result_queue, dataset_name, base_save_dir, log_dir, epochs)

        results = []
        total_tasks = len(configurations_with_truth)

        # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆæ ¹æ®ä»»åŠ¡æ•°é‡è°ƒæ•´ï¼‰
        timeout = max(3600, total_tasks * 600)  # è‡³å°‘1å°æ—¶ï¼Œæˆ–æ¯ä¸ªä»»åŠ¡10åˆ†é’Ÿ

        # æ”¶é›†ç»“æœ
        for i in range(total_tasks):
            try:
                result = result_queue.get(timeout=timeout)
                results.append(result)
                
                # å®æ—¶ä¿å­˜ç»“æœ
                results_save_path = os.path.join(base_save_dir, "test_results.json")
                with open(results_save_path, "w", encoding="utf-8") as f:
                    converted_results = convert_numpy_types(results)
                    json.dump(converted_results, f, indent=2, ensure_ascii=False)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress_percent = (i + 1) / total_tasks * 100
                print(f"ğŸ“Š è¿›åº¦: {i + 1}/{total_tasks} ({progress_percent:.1f}%)")
                
                if result.get('status') == 'success':
                    print(f"âœ… å®Œæˆ: {result['description']}")
                    print(f"  åŸå§‹: {result['accuracies']['original']:.2f}% (True: {result['true_accuracy']:.2f}%)")
                    if 'static_quant' in result['accuracies']:
                        print(f"  é™æ€é‡åŒ–: {result['accuracies']['static_quant']:.2f}% (True: {result['true_quant_accuracy']:.2f}%)")
                    if 'qat' in result['accuracies']:
                        print(f"  QAT: {result['accuracies']['qat']:.2f}% (True: {result['true_qat_accuracy']:.2f}%)")
                else:
                    print(f"âŒ å¤±è´¥: {result['description']} - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                print("-" * 80)
                
            except Exception as e:
                print(f"âš ï¸ è·å–ç»“æœè¶…æ—¶æˆ–é”™è¯¯: {e}")
                break

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ç»“æŸ
        for p in processes:
            p.join(timeout=30)
            if p.is_alive():
                p.terminate()
        
        # æœ€ç»ˆä¿å­˜ä¸€æ¬¡ç»“æœ
        results_save_path = os.path.join(base_save_dir, "test_results.json")
        with open(results_save_path, "w", encoding="utf-8") as f:
            converted_results = convert_numpy_types(results)
            json.dump(converted_results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {results_save_path}")
        
        # åˆ†æç»“æœ
        analyze_results(results, base_save_dir)

    except KeyboardInterrupt:
        print("ğŸ›‘ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        # ç»ˆæ­¢æ‰€æœ‰å­è¿›ç¨‹
        for p in processes:
            if p.is_alive():
                p.terminate()
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()